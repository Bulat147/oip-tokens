<!doctype html>
<html lang="ru">
 <head>
  <title>Как я обошел современные GPT модели с помощью GPT2-small на задачах рассуждения / Хабр</title>
  <meta property="fb:app_id" content="444736788986613">
  <meta property="fb:pages" content="472597926099084">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@habr_com">
  <meta property="og:site_name" content="Хабр">
  <link href="https://habr.com/ru/rss/post/907208/?fl=ru" type="application/rss+xml" title rel="alternate" name="rss">
  <link href="https://habr.com/ru/articles/907208/" rel="canonical" data-hid="e3fa780">
  <link rel="image_src" href="https://habrastorage.org/getpro/habr/upload_files/8e9/5fa/464/8e95fa464ba9ba29a11719806039d224.png" data-hid="2a79c45">
  <link rel="amphtml" href="https://habr.com/ru/amp/publications/907208/">
  <meta property="og:title" content="Как я обошел современные GPT модели с помощью GPT2-small на задачах рассуждения">
  <meta name="twitter:title" content="Как я обошел современные GPT модели с помощью GPT2-small на задачах рассуждения">
  <meta name="aiturec:title" content="Как я обошел современные GPT модели с помощью GPT2-small на задачах рассуждения">
  <meta name="description" content="Не так давно я уже писал статью по такому необычному явлению, как гроккинг - отложенная генерализация. Если долго тренировать модель на наборе данных, то тестовая точность достигнет 100% и модель...">
  <meta itemprop="description" content="Не так давно я уже писал статью по такому необычному явлению, как гроккинг - отложенная генерализация. Если долго тренировать модель на наборе данных, то тестовая точность достигнет 100% и модель...">
  <meta property="og:description" content="Не так давно я уже писал статью по такому необычному явлению, как гроккинг - отложенная генерализация. Если долго тренировать модель на наборе данных, то тестовая точность достигнет 100% и модель...">
  <meta name="twitter:description" content="Не так давно я уже писал статью по такому необычному явлению, как гроккинг - отложенная генерализация. Если долго тренировать модель на наборе данных, то тестовая точность достигнет 100% и модель...">
  <meta property="aiturec:description" content="Не так давно я уже писал статью по такому необычному явлению, как гроккинг - отложенная генерализация. Если долго тренировать модель на наборе данных, то тестовая точность достигнет 100% и модель...">
  <meta itemprop="image" content="https://habrastorage.org/getpro/habr/upload_files/8e9/5fa/464/8e95fa464ba9ba29a11719806039d224.png">
  <meta property="og:image" content="https://habrastorage.org/getpro/habr/upload_files/8e9/5fa/464/8e95fa464ba9ba29a11719806039d224.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="aiturec:image" content="https://habrastorage.org/getpro/habr/upload_files/8e9/5fa/464/8e95fa464ba9ba29a11719806039d224.png">
  <meta name="twitter:image" content="https://habrastorage.org/getpro/habr/upload_files/8e9/5fa/464/8e95fa464ba9ba29a11719806039d224.png">
  <meta property="vk:image" content="https://habrastorage.org/getpro/habr/upload_files/8e9/5fa/464/8e95fa464ba9ba29a11719806039d224.png?format=vk">
  <meta property="vk:image" content="https://habrastorage.org/getpro/habr/upload_files/8e9/5fa/464/8e95fa464ba9ba29a11719806039d224.png?format=vk">
  <meta property="aiturec:item_id" content="907208">
  <meta property="aiturec:datetime" content="2025-05-06T06:13:07.000Z">
  <meta content="https://habr.com/ru/articles/907208/" property="og:url">
  <meta property="og:type" content="article">
  <meta property="og:locale" content="ru_RU">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta name="keywords" content="искусственный интеллект, трансформеры, гроккинг, машинное+обучение, ai, рассуждение">
  <script type="application/ld+json" data-hid="1e0f0a2">{"@context":"http:\/\/schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/habr.com\/ru\/articles\/907208\/"},"headline":"Как я обошел современные GPT модели с помощью GPT2-small на задачах рассуждения","datePublished":"2025-05-06T09:13:07+03:00","dateModified":"2025-05-07T01:05:45+03:00","author":{"@type":"Person","name":"Roman Abramov"},"publisher":{"@type":"Organization","name":"Habr","logo":{"@type":"ImageObject","url":"https:\/\/habrastorage.org\/webt\/a_\/lk\/9m\/a_lk9mjkccjox-zccjrpfolmkmq.png"}},"description":"Не так давно я уже писал статью по такому необычному явлению, как гроккинг - отложенная генерализация. Если долго тренировать модель на наборе данных, то тестова...","url":"https:\/\/habr.com\/ru\/articles\/907208\/#post-content-body","about":["h_machine_learning","h_artificial_intelligence","h_popular_science","f_develop","f_popsci"],"image":["https:\/\/habr.com\/share\/publication\/907208\/465d55abdbcaac07e7e901bce4df6c41\/","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/8e9\/5fa\/464\/8e95fa464ba9ba29a11719806039d224.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/acd\/46b\/561\/acd46b561145ee5e5f106613cda92a84.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/3e0\/a69\/9d5\/3e0a699d5a1dc3f0ddf655a1a1d5ad89.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/0fc\/47e\/8da\/0fc47e8daab2ea31f758925cb21e696a.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/34a\/97b\/30b\/34a97b30bc2afd3984d65bd26cc17755.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/7c7\/847\/c1d\/7c7847c1dfd8f7b2e52c59bab6ee9951.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/08f\/64f\/750\/08f64f750600e3b8037de8a105f32ef0.png","https:\/\/habrastorage.org\/getpro\/habr\/upload_files\/338\/ecb\/2cc\/338ecb2cc54d5d4d7171a8bed57f1554.png"]}</script>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover,maximum-scale=1,user-scalable=0">
  <meta name="referrer" content="unsafe-url">
  <style>
      /* cyrillic-ext */
      @font-face {
        font-family: 'Fira Sans';
        font-style: normal;
        font-weight: 400;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/firasans/v17/va9E4kDNxMZdWfMOD5VvmojLazX3dGTP.woff2) format('woff2');
        unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
      }

      /* cyrillic */
      @font-face {
        font-family: 'Fira Sans';
        font-style: normal;
        font-weight: 400;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/firasans/v17/va9E4kDNxMZdWfMOD5Vvk4jLazX3dGTP.woff2) format('woff2');
        unicode-range: U+0301, U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
      }

      /* latin-ext */
      @font-face {
        font-family: 'Fira Sans';
        font-style: normal;
        font-weight: 400;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/firasans/v17/va9E4kDNxMZdWfMOD5VvmYjLazX3dGTP.woff2) format('woff2');
        unicode-range: U+0100-02AF, U+0304, U+0308, U+0329, U+1E00-1E9F, U+1EF2-1EFF, U+2020, U+20A0-20AB, U+20AD-20C0, U+2113, U+2C60-2C7F, U+A720-A7FF;
      }

      /* latin */
      @font-face {
        font-family: 'Fira Sans';
        font-style: normal;
        font-weight: 400;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/firasans/v17/va9E4kDNxMZdWfMOD5Vvl4jLazX3dA.woff2) format('woff2');
        unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+0304, U+0308, U+0329, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
      }

      /* cyrillic-ext */
      @font-face {
        font-family: 'Fira Sans';
        font-style: normal;
        font-weight: 500;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/firasans/v17/va9B4kDNxMZdWfMOD5VnZKveSxf6Xl7Gl3LX.woff2) format('woff2');
        unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
      }

      /* cyrillic */
      @font-face {
        font-family: 'Fira Sans';
        font-style: normal;
        font-weight: 500;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/firasans/v17/va9B4kDNxMZdWfMOD5VnZKveQhf6Xl7Gl3LX.woff2) format('woff2');
        unicode-range: U+0301, U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
      }

      /* latin-ext */
      @font-face {
        font-family: 'Fira Sans';
        font-style: normal;
        font-weight: 500;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/firasans/v17/va9B4kDNxMZdWfMOD5VnZKveSBf6Xl7Gl3LX.woff2) format('woff2');
        unicode-range: U+0100-02AF, U+0304, U+0308, U+0329, U+1E00-1E9F, U+1EF2-1EFF, U+2020, U+20A0-20AB, U+20AD-20C0, U+2113, U+2C60-2C7F, U+A720-A7FF;
      }

      /* latin */
      @font-face {
        font-family: 'Fira Sans';
        font-style: normal;
        font-weight: 500;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/firasans/v17/va9B4kDNxMZdWfMOD5VnZKveRhf6Xl7Glw.woff2) format('woff2');
        unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+0304, U+0308, U+0329, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
      }

      /* cyrillic-ext */
      @font-face {
        font-family: 'Fira Sans';
        font-style: normal;
        font-weight: 700;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/firasans/v17/va9B4kDNxMZdWfMOD5VnLK3eSxf6Xl7Gl3LX.woff2) format('woff2');
        unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
      }

      /* cyrillic */
      @font-face {
        font-family: 'Fira Sans';
        font-style: normal;
        font-weight: 700;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/firasans/v17/va9B4kDNxMZdWfMOD5VnLK3eQhf6Xl7Gl3LX.woff2) format('woff2');
        unicode-range: U+0301, U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
      }

      /* latin-ext */
      @font-face {
        font-family: 'Fira Sans';
        font-style: normal;
        font-weight: 700;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/firasans/v17/va9B4kDNxMZdWfMOD5VnLK3eSBf6Xl7Gl3LX.woff2) format('woff2');
        unicode-range: U+0100-02AF, U+0304, U+0308, U+0329, U+1E00-1E9F, U+1EF2-1EFF, U+2020, U+20A0-20AB, U+20AD-20C0, U+2113, U+2C60-2C7F, U+A720-A7FF;
      }

      /* latin */
      @font-face {
        font-family: 'Fira Sans';
        font-style: normal;
        font-weight: 700;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/firasans/v17/va9B4kDNxMZdWfMOD5VnLK3eRhf6Xl7Glw.woff2) format('woff2');
        unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+0304, U+0308, U+0329, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
      }
    </style>
  <link rel="preload" href="https://assets.habr.com/habr-web/css/theme/light-v1.css" as="style" media="(prefers-color-scheme: light)">
  <link rel="preload" href="https://assets.habr.com/habr-web/css/theme/dark-v1.css" as="style" media="(prefers-color-scheme: dark)">
  <link id="light-colors" rel="stylesheet" href="https://assets.habr.com/habr-web/css/theme/light-v1.css" media="(prefers-color-scheme: light)">
  <link id="dark-colors" rel="stylesheet" href="https://assets.habr.com/habr-web/css/theme/dark-v1.css" media="(prefers-color-scheme: dark)">
  <script>window.i18nFetch = new Promise((res, rej) => {
          const xhr = new XMLHttpRequest();
          xhr.open('GET', '/js/i18n/ru-compiled.635b6c39236ebd33fa716c71ab0131a0.json');
          xhr.responseType = 'json';
          xhr.onload = function(e) {
            if (this.status === 200) {
              res({ru: xhr.response});
            } else {
              rej(e);
            }
          };
          xhr.send();
        });</script>
  <style>
      .grecaptcha-badge {
        visibility: hidden;
      }
    </style>
  <meta name="habr-version" content="2.241.0">
  <meta name="apple-mobile-web-app-status-bar-style" content="#303b44">
  <meta name="msapplication-TileColor" content="#629FBC">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link rel="shortcut icon" type="image/png" sizes="16x16" href="https://assets.habr.com/habr-web/img/favicons/favicon-16.png">
  <link rel="shortcut icon" type="image/png" sizes="32x32" href="https://assets.habr.com/habr-web/img/favicons/favicon-32.png">
  <link rel="apple-touch-icon" type="image/png" sizes="76x76" href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-76.png">
  <link rel="apple-touch-icon" type="image/png" sizes="120x120" href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.png">
  <link rel="apple-touch-icon" type="image/png" sizes="152x152" href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-152.png">
  <link rel="apple-touch-icon" type="image/png" sizes="180x180" href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-180.png">
  <link rel="apple-touch-icon" type="image/png" sizes="256x256" href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-256.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)" href="https://assets.habr.com/habr-web/img/splashes/splash_1136x640.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)" href="https://assets.habr.com/habr-web/img/splashes/splash_2436x1125.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)" href="https://assets.habr.com/habr-web/img/splashes/splash_1792x828.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)" href="https://assets.habr.com/habr-web/img/splashes/splash_828x1792.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)" href="https://assets.habr.com/habr-web/img/splashes/splash_1334x750.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)" href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2668.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)" href="https://assets.habr.com/habr-web/img/splashes/splash_2208x1242.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)" href="https://assets.habr.com/habr-web/img/splashes/splash_1125x2436.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)" href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2208.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)" href="https://assets.habr.com/habr-web/img/splashes/splash_2732x2048.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)" href="https://assets.habr.com/habr-web/img/splashes/splash_2688x1242.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)" href="https://assets.habr.com/habr-web/img/splashes/splash_2224x1668.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)" href="https://assets.habr.com/habr-web/img/splashes/splash_750x1334.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)" href="https://assets.habr.com/habr-web/img/splashes/splash_2048x2732.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)" href="https://assets.habr.com/habr-web/img/splashes/splash_2388x1668.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)" href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2224.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)" href="https://assets.habr.com/habr-web/img/splashes/splash_640x1136.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)" href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2388.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)" href="https://assets.habr.com/habr-web/img/splashes/splash_2048x1536.png">
  <link rel="apple-touch-startup-image" media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)" href="https://assets.habr.com/habr-web/img/splashes/splash_1536x2048.png">
  <link rel="mask-icon" color="#77a2b6" href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.svg">
  <link crossorigin="use-credentials" href="/manifest.webmanifest" rel="manifest">
  <script async src="https://unpkg.com/pwacompat" crossorigin="anonymous"></script>
  <script>window.yaContextCb = window.yaContextCb || []</script>
  <script src="https://yandex.ru/ads/system/context.js" async></script>
  <link rel="preload" href="https://assets.habr.com/habr-web/css/chunk-vendors.04465f7c.css" as="style">
  <link rel="preload" href="https://assets.habr.com/habr-web/js/chunk-vendors.978df117.js" as="script">
  <link rel="preload" href="https://assets.habr.com/habr-web/css/app.8599692f.css" as="style">
  <link rel="preload" href="https://assets.habr.com/habr-web/js/app.58b8c457.js" as="script">
  <link rel="stylesheet" href="https://assets.habr.com/habr-web/css/chunk-vendors.04465f7c.css">
  <link rel="stylesheet" href="https://assets.habr.com/habr-web/css/app.8599692f.css">
 </head>
 <body>
  <div id="mount">
   <div id="app">
    <div class="tm-layout__wrapper">
     <!--[--><!---->
     <div></div><!---->
     <header class="tm-header" data-test-id="header">
      <div class="tm-page-width">
       <!--[-->
       <div class="tm-header__container">
        <!----><span class="tm-header__logo-wrap"><a class="tm-header__logo tm-header__logo_hl-ru tm-header__logo" href="/ru/">
          <svg class="tm-svg-img tm-header__icon" height="16" width="16">
           <title>
            Хабр
           </title><use xlink:href="/img/habr-logo-ru.svg#logo"></use>
          </svg></a><span style="display:none;" class="tm-header__beta-sign">β</span></span><!--[-->
        <div class="tm-dropdown tm-header__projects">
         <div class="tm-dropdown__head">
          <!--[-->
          <button class="tm-header__dropdown-toggle">
           <svg class="tm-svg-img tm-header__icon tm-header__icon_dropdown" height="16" width="16">
            <title>
             Открыть список
            </title><use xlink:href="/img/megazord-v28.7909a852..svg#arrow-down"></use>
           </svg></button><!--]-->
         </div><!---->
        </div><a href="/ru/sandbox/start/" class="tm-header__become-author-btn">Как стать автором</a>
        <div class="tm-feature tm-feature tm-feature_variant-inline tm-header__feature">
         <!---->
        </div><!----><!--]--><!---->
       </div><!--]-->
      </div>
     </header>
     <div class="tm-layout">
      <div class="tm-page-progress-bar"></div>
      <div class="tm-base-layout__header_is-sticky tm-base-layout__header" data-menu-sticky="true">
       <div class="tm-page-width">
        <!--[-->
        <div class="tm-base-layout__header-wrapper">
         <div class="tm-main-menu">
          <div class="tm-main-menu__section">
           <nav class="tm-main-menu__section-content">
            <!--[--><a class="tm-main-menu__item" data-test-id="main-menu-item" href="/ru/feed/">Моя лента</a><!--]--><!--[--><a class="tm-main-menu__item" href="/ru/articles/">Все потоки</a><!--]--><!--[--><!--[--><a class="tm-main-menu__item" data-test-id="main-menu-item" href="/ru/flows/develop/">Разработка</a><!--]--><!--[--><a class="tm-main-menu__item" data-test-id="main-menu-item" href="/ru/flows/admin/">Администрирование</a><!--]--><!--[--><a class="tm-main-menu__item" data-test-id="main-menu-item" href="/ru/flows/design/">Дизайн</a><!--]--><!--[--><a class="tm-main-menu__item" data-test-id="main-menu-item" href="/ru/flows/management/">Менеджмент</a><!--]--><!--[--><a class="tm-main-menu__item" data-test-id="main-menu-item" href="/ru/flows/marketing/">Маркетинг</a><!--]--><!--[--><a class="tm-main-menu__item" data-test-id="main-menu-item" href="/ru/flows/popsci/">Научпоп</a><!--]--><!--]-->
           </nav>
          </div>
         </div>
         <div class="tm-header-user-menu tm-base-layout__user-menu">
          <a href="/ru/search/" class="tm-header-user-menu__item tm-header-user-menu__search" data-test-id="search-button">
           <svg class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_search tm-header-user-menu__icon_dark" height="24" width="24">
            <title>
             Поиск
            </title><use xlink:href="/img/megazord-v28.7909a852..svg#search"></use>
           </svg></a><!----><!---->
          <div class="tm-header-user-menu__item tm-header-user-menu__write">
           <div>
            <svg class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_write tm-header-user-menu__icon_dark" height="24" width="24">
             <title>
              Написать публикацию
             </title><use xlink:href="/img/megazord-v28.7909a852..svg#write"></use>
            </svg>
           </div><!---->
          </div><!--[-->
          <div class="tm-header-user-menu__item">
           <button class="tm-header-user-menu__toggle" data-test-id="user-menu-settings">
            <svg class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_dark" height="24" width="24">
             <title>
              Настройки
             </title><use xlink:href="/img/megazord-v28.7909a852..svg#page-settings"></use>
            </svg></button>
          </div><a href="https://habr.com/kek/v1/auth/habrahabr/?back=/ru/articles/907208/&amp;hl=ru" rel="nofollow" class="tm-header-user-menu__item"><!--[-->
           <button class="btn btn_solid btn_small tm-header-user-menu__login" type="button"><!--[-->Войти<!--]--></button><!--]--></a><!--]--><!----><!--teleport start--><!--teleport end--><!---->
         </div>
        </div><!--]-->
       </div>
      </div><!---->
      <div class="tm-page-width">
       <!--[--><!--]-->
      </div>
      <main class="tm-layout__container">
       <div class="tm-page" hl="ru" data-async-called="true" style="--5ab2e5a8:16px;--44c4f6f6:100%;--45ba7a3b:0;">
        <div class="tm-page-width">
         <!--[--><!---->
         <div class="tm-page__wrapper">
          <div class="tm-page__main_has-sidebar tm-page__main">
           <div class="pull-down">
            <!---->
            <div class="pull-down__header" style="height:0px;">
             <div class="pull-down__content" style="bottom:10px;">
              <svg class="tm-svg-img pull-down__icon pull-down__arrow" height="24" width="24">
               <title>
                Обновить
               </title><use xlink:href="/img/megazord-v28.7909a852..svg#pull-arrow"></use>
              </svg>
             </div>
            </div><!--[--><!--[--><!---->
            <div class="tm-article-presenter">
             <!--[--><!--]-->
             <div class="tm-article-presenter__body" data-test-id="article-body">
              <div class="tm-misprint-area">
               <div class="tm-misprint-area__wrapper">
                <!--[-->
                <article class="tm-article-presenter__content tm-article-presenter__content_narrow">
                 <!--[-->
                 <div class="tm-article-presenter__header">
                  <!--[--><!--]-->
                  <div class="tm-article-snippet tm-article-snippet tm-article-presenter__snippet">
                   <!--[--><!--]-->
                   <div class="tm-article-snippet__meta-container">
                    <div class="tm-article-snippet__meta">
                     <span class="tm-user-info tm-article-snippet__author"><a href="/ru/users/perfect_startup/" class="tm-user-info__userpic" data-test-id="user-info-pic" title="perfect_startup">
                       <div class="tm-entity-image">
                        <img alt="" class="tm-entity-image__pic" height="24" src="//habrastorage.org/r/w48/getpro/habr/avatars/32b/a19/2af/32ba192af10fcb9adaedc42807340c37.jpg" width="24">
                       </div></a><span class="tm-user-info__user tm-user-info__user_appearance-default" data-test-id="user-info-description"><a href="/ru/users/perfect_startup/" class="tm-user-info__username">perfect_startup <!----></a><!--[--><span class="tm-article-datetime-published"><time datetime="2025-05-06T06:13:07.000Z" title="2025-05-06, 09:13">вчера в 09:13</time></span><!--]--></span></span>
                    </div><!---->
                   </div>
                   <h1 class="tm-title tm-title_h1" lang="ru" data-test-id="articleTitle"><span>Как я обошел современные GPT модели с помощью GPT2-small на задачах рассуждения</span></h1>
                   <div class="tm-article-snippet__stats" data-test-id="articleStats">
                    <div class="tm-article-complexity tm-article-complexity_complexity-low">
                     <span class="tm-svg-icon__wrapper tm-article-complexity__icon">
                      <svg class="tm-svg-img tm-svg-icon" height="24" width="24">
                       <title>
                        Уровень сложности
                       </title><use xlink:href="/img/megazord-v28.7909a852..svg#complexity-low"></use>
                      </svg></span><span class="tm-article-complexity__label">Простой</span>
                    </div>
                    <div class="tm-article-reading-time">
                     <span class="tm-svg-icon__wrapper tm-article-reading-time__icon">
                      <svg class="tm-svg-img tm-svg-icon" height="24" width="24">
                       <title>
                        Время на прочтение
                       </title><use xlink:href="/img/megazord-v28.7909a852..svg#clock"></use>
                      </svg></span><span class="tm-article-reading-time__label">9 мин</span>
                    </div><span class="tm-icon-counter tm-data-icons__item">
                     <svg class="tm-svg-img tm-icon-counter__icon" height="24" width="24">
                      <title>
                       Количество просмотров
                      </title><use xlink:href="/img/megazord-v28.7909a852..svg#counter-views"></use>
                     </svg><span class="tm-icon-counter__value" title="3421">3.4K</span></span>
                   </div>
                   <div class="tm-publication-hubs__container" data-test-id="articleHubsList">
                    <div class="tm-publication-hubs">
                     <!--[--><span class="tm-publication-hub__link-container"><a href="/ru/hubs/machine_learning/" class="tm-publication-hub__link"><!--[--><span>Машинное обучение</span><span class="tm-article-snippet__profiled-hub" title="Профильный хаб">*</span><!--]--></a></span><span class="tm-publication-hub__link-container"><a href="/ru/hubs/artificial_intelligence/" class="tm-publication-hub__link"><!--[--><span>Искусственный интеллект</span><!----><!--]--></a></span><span class="tm-publication-hub__link-container"><a href="/ru/hubs/popular_science/" class="tm-publication-hub__link"><!--[--><span>Научно-популярное</span><!----><!--]--></a></span><!--]-->
                    </div>
                   </div>
                   <div class="tm-article-labels" data-test-id="articleLabels">
                    <div class="tm-article-labels__container">
                     <div class="tm-publication-label tm-publication-label_variant-review">
                      <span>Обзор</span>
                     </div><!--[--><!--]-->
                    </div>
                   </div><!----><!---->
                  </div>
                 </div><!--[--><!---->
                 <div class="tm-article-body" data-gallery-root lang="ru">
                  <div>
                   <!--[--><!--]-->
                  </div>
                  <div id="post-content-body">
                   <div>
                    <div class="article-formatted-body article-formatted-body article-formatted-body_version-2">
                     <div xmlns="http://www.w3.org/1999/xhtml">
                      <p>Не так давно я уже писал статью по такому необычному явлению, как гроккинг - отложенная генерализация. Если долго тренировать модель на наборе данных, то тестовая точность достигнет 100% и модель станет безошибочно решать задачу. Звучит круто! Но вот проблема - никто до сих пор не мог применить гроккинг на задачах из реального мира, а мы это сделали и сейчас публикуемся на крупнейшей МЛ конференции. Если интересно, как мы этого достигли, то прошу под кат.</p>
                      <figure class="full-width ">
                       <img src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/8e9/5fa/464/8e95fa464ba9ba29a11719806039d224.png" alt="&nbsp;" title="&nbsp;" width="2042" height="1371" sizes="(max-width: 780px) 100vw, 50vw" srcset="https://habrastorage.org/r/w780/getpro/habr/upload_files/8e9/5fa/464/8e95fa464ba9ba29a11719806039d224.png 780w,
       https://habrastorage.org/r/w1560/getpro/habr/upload_files/8e9/5fa/464/8e95fa464ba9ba29a11719806039d224.png 781w" loading="lazy" decode="async">
                       <div>
                        <figcaption>
                         &nbsp;
                        </figcaption>
                       </div>
                      </figure>
                      <p>Привет! Меня зовут Роман и я сейчас получаю Ph.D. в Мюнхене. Одной из тем моей кандидатской является память и гроккинг. Последняя статья как раз посвящена этому необычному явлению, с ней мы проходим на большую конференцию и боремся за первое место в <a href="https://huggingface.co/papers/2504.20752" rel="noopener noreferrer nofollow">Paper of The Day</a> - ваша поддержка будет незаменима.</p>
                      <h2>Гроккинг</h2>
                      <p>Представим, что мы собрали данные для ИИ-калькулятора. Например, 500 примеров вида: 2 × 3 = 6, 4 × 2 = 8 и так далее. Мы обучили модель на этих данных и теперь проверяем её работу на новых примерах, которых она раньше не видела: 10 × 10 = 100, 10 × 11 = 110. Если модель верно справляется с такой задачей, значит, она успешно <strong>обобщает</strong> полученные знания. Если же модель не дала ни одного правильного ответа, то обобщения не произошло — скорее всего, модель просто «<strong>запомнила</strong>» тренировочный набор данных.</p>
                      <blockquote>
                       <p><strong>Обобщение</strong>&nbsp;в контексте машинного обучения — это способность модели применять знания и навыки к новым, ранее не встречавшимся данным или ситуациям.</p>
                      </blockquote>
                      <p>Современные подходы в искусственном интеллекте утверждают: если модель демонстрирует <em>высокие</em> результаты на тренировочных данных, но <em>низкие</em> — на тестовых, это называется <strong>переобучением</strong>. Чтобы избежать этого, обычно расширяют обучающую выборку, применяют регуляризацию или используют другие техники. При наличии большого объёма тренировочных данных, как и при регуляризации, модель физически не способна всё запомнить — ей приходится искать более эффективные подходы.</p>
                      <p>Однако далеко не всегда возможно или рационально расширять выборку миллионами новых примеров или применять жёсткую регуляризацию — да и не всегда эти подходы дают желаемый результат. Возникает естественный вопрос: <em>существуют ли альтернативные пути достижения качественного обобщения</em>? Именно здесь и проявляет себя феномен «<strong>гроккинга</strong>», предлагающий совершенно иной подход к <strong>обобщению</strong> моделей.</p>
                      <blockquote>
                       <p><strong>Гроккинг</strong>— это феномен&nbsp;<strong><em>отложенного</em></strong>&nbsp;обобщения модели на небольших наборах данных.</p>
                      </blockquote>
                      <figure class="full-width ">
                       <img src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/acd/46b/561/acd46b561145ee5e5f106613cda92a84.png" alt="Метрики на тренировочной и тестовой выборке для задачи модульного деления. Модель через 100 итерацией достигает 100%, и лишь через 1 миллион итераций достигает такого же результата на тестовой." title="Метрики на тренировочной и тестовой выборке для задачи модульного деления. Модель через 100 итерацией достигает 100%, и лишь через 1 миллион итераций достигает такого же результата на тестовой." width="1560" height="1171" sizes="(max-width: 780px) 100vw, 50vw" srcset="https://habrastorage.org/r/w780/getpro/habr/upload_files/acd/46b/561/acd46b561145ee5e5f106613cda92a84.png 780w,
       https://habrastorage.org/r/w1560/getpro/habr/upload_files/acd/46b/561/acd46b561145ee5e5f106613cda92a84.png 781w" loading="lazy" decode="async">
                       <div>
                        <figcaption>
                         Метрики на тренировочной и тестовой выборке для задачи модульного деления. Модель через 100 итерацией достигает 100%, и лишь через 1 миллион итераций достигает такого же результата на тестовой.
                        </figcaption>
                       </div>
                      </figure>
                      <p>Из графика можно увидеть, что отложенность у обобщения довольно значительная: модель запомнила тренировочную выборку за тысячу итераций, а для обобщения на тестовой потребовался миллион. Если перенести эти масштабы на современные языковые модели, обучение которых занимает недели или месяцы, гроккинг увеличил бы этот период до десятков лет. Неудивительно, что данному явлению уделяется так мало внимания — на данный момент оно не слишком эффективно.</p>
                      <blockquote>
                       <p>Если интересно узнать больше, то я написал целую статью вместе с практикой - можете сами <a href="https://habr.com/ru/articles/840136/" rel="noopener noreferrer nofollow">попробовать пронаблюдать гроккинг</a>.</p>
                      </blockquote>
                      <h2>Почему гроккинг не применяли на реальных данных?</h2>
                      <p>Помимо упомянутой неэффективности, существует и другая проблема. Несмотря на то, что в некоторых исследованиях удалось добиться существенного ускорения гроккинга, остаётся вопрос о его универсальности: гроккинг проявляется далеко не на всех задачах. Более того, до сих пор нет чёткого понимания того, какие именно условия, <em>помимо продолжительного обучения</em>, необходимы для того, чтобы этот феномен вообще возник.</p>
                      <p>Однако не так давно вышла статья, которая проливает свет на необходимые условия гроккинга. Авторы создали абстрактный набор данных, чтобы имитировать <strong>n-шаговое рассуждение. </strong>Их набор данных состоял из задач сравнения и композиции. Для простоты понимания, превратим этот абстрактный набор данных во что-то осмысленное.</p>
                      <p>Например, у нас есть <strong>атомарные факты:</strong></p>
                      <blockquote>
                       <p>Атомарные факты – это <strong>простые, неделимые утверждения</strong>, которые не зависят от других фактов.</p>
                      </blockquote>
                      <ul>
                       <li>
                        <p>Миша женат на Свете</p></li>
                       <li>
                        <p>Света дружит с Викой</p></li>
                      </ul>
                      <p>Отсюда можно получить <strong>выведенные факт:</strong></p>
                      <blockquote>
                       <p><strong>Выведенные факты - </strong>Это факты, которые <strong>получаются путём логической комбинации</strong> из других фактов</p>
                      </blockquote>
                      <ul>
                       <li>
                        <p>подруга жены Миши — Вика.</p></li>
                      </ul>
                      <figure class="full-width ">
                       <img src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/3e0/a69/9d5/3e0a699d5a1dc3f0ddf655a1a1d5ad89.png" alt="Задача композиции " title="Задача композиции " width="1560" height="733" sizes="(max-width: 780px) 100vw, 50vw" srcset="https://habrastorage.org/r/w780/getpro/habr/upload_files/3e0/a69/9d5/3e0a699d5a1dc3f0ddf655a1a1d5ad89.png 780w,
       https://habrastorage.org/r/w1560/getpro/habr/upload_files/3e0/a69/9d5/3e0a699d5a1dc3f0ddf655a1a1d5ad89.png 781w" loading="lazy" decode="async">
                       <div>
                        <figcaption>
                         Задача композиции
                        </figcaption>
                       </div>
                      </figure>
                      <p>Обратите внимание на важную деталь: мы специально не упоминали Свету напрямую в формулировке вопроса, иначе задача композиции превратилась бы из двухшаговой в одношаговую. В такой задаче модели необходимо выполнить сразу несколько шагов логических рассуждений, чтобы найти конечный ответ.</p>
                      <p>Например, вопрос звучит так:</p>
                      <ul>
                       <li>
                        <p>Кто подруга жены Мишы?</p></li>
                      </ul>
                      <p>Модели необходимо проделать два шага рассуждений:</p>
                      <ul>
                       <li>
                        <p>Понять, на ком женат Миша (Света)</p></li>
                       <li>
                        <p>Найти с кем дружит Света (Вика)</p></li>
                      </ul>
                      <p>Так вот, в задачах рассуждения для появления гроккинга необходимо иметь определенный коэффициент выведенных фактов к атомарным. Для этого набора данных он был 3.6, то есть понимаете, что выведенных фактов по сравнению с атомарными<strong> должно быть в 3.6 раза больше</strong>! Как мы понимаем, в реальном мире такое очень редко встречается.</p>
                      <blockquote>
                       <p>Чтобы лучше понять, насколько все плохо, можем посмотреть вместе на типичные данные для обучения LLM: википедия. Откройте любую страницу и посчитайте, сколько на одной странице атомарных фактов и выведенных. У меня получилось 1000 атомарных фактов к 12 выведенным на случайной странице. Как мы далеки от нашего коэффициента!</p>
                      </blockquote>
                      <figure class="full-width ">
                       <img src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/0fc/47e/8da/0fc47e8daab2ea31f758925cb21e696a.png" alt="(Слева) График тестовой метрики от соотношения выведенных / атомарных фактов. Можно заметить, что если соотношения 3.6 (то есть на 1 атомарный факт приходится 3.6 выведенных), то сходимость не наступает. В целом, чем выше соотношение, тем быстрее сходимость. (Справа) График тестовой метрики в зависимости от размера набора данных - 2, 5 и 10 тысяч. " title="(Слева) График тестовой метрики от соотношения выведенных / атомарных фактов. Можно заметить, что если соотношения 3.6 (то есть на 1 атомарный факт приходится 3.6 выведенных), то сходимость не наступает. В целом, чем выше соотношение, тем быстрее сходимость. (Справа) График тестовой метрики в зависимости от размера набора данных - 2, 5 и 10 тысяч. " width="1560" height="732" sizes="(max-width: 780px) 100vw, 50vw" srcset="https://habrastorage.org/r/w780/getpro/habr/upload_files/0fc/47e/8da/0fc47e8daab2ea31f758925cb21e696a.png 780w,
       https://habrastorage.org/r/w1560/getpro/habr/upload_files/0fc/47e/8da/0fc47e8daab2ea31f758925cb21e696a.png 781w" loading="lazy" decode="async">
                       <div>
                        <figcaption>
                         (Слева) График тестовой метрики от соотношения выведенных / атомарных фактов. Можно заметить, что если соотношения 3.6 (то есть на 1 атомарный факт приходится 3.6 выведенных), то сходимость не наступает. В целом, чем выше соотношение, тем быстрее сходимость. (Справа) График тестовой метрики в зависимости от размера набора данных - 2, 5 и 10 тысяч.
                        </figcaption>
                       </div>
                      </figure>
                      <h2>Работает ли это на реальных задачах?</h2>
                      <p>Именно таким вопросом я задался и решил попробовать применить данных подход к датасету <a href="https://paperswithcode.com/dataset/2wikimultihopqa" rel="noopener noreferrer nofollow">2WikiMultiHopQA</a>. Он составлен из страниц википедии и содержит n-шаговые рассуждения. Всего там 4 разных задачи:</p>
                      <ul>
                       <li>
                        <p>Сравнение</p></li>
                       <li>
                        <p>Композиция</p></li>
                       <li>
                        <p>Умозаключение</p></li>
                       <li>
                        <p>Связующее сравнение</p></li>
                      </ul>
                      <p>Для простоты, возьмем только первые два набора задач. Вот некоторые примеры из них:</p>
                      <p><strong>Сравнение</strong></p>
                      <p>Атомарные факты:</p>
                      <ul>
                       <li>
                        <p>Страна Лувра – Франция</p></li>
                       <li>
                        <p>Страна Эльфевой Башни – Франция</p></li>
                      </ul>
                      <p>Соответственно, вопрос, который мы задаем модели будет:</p>
                      <ul>
                       <li>
                        <p>Находится ли Музей Лува и Эйфелева Башня в одной стране?</p></li>
                      </ul>
                      <p><strong>Композиция</strong></p>
                      <p>Атомарные факты:</p>
                      <ul>
                       <li>
                        <p>Режиссёр фильма «Месье Такси» — Андре Юнебель</p></li>
                       <li>
                        <p>Андре Юнебель умер в Ницце</p></li>
                      </ul>
                      <p>Соответственно, вопрос, который мы задаем модели будет:</p>
                      <ul>
                       <li>
                        <p>Где умер режиссёр фильма «Месье Такси»?</p></li>
                      </ul>
                      <blockquote>
                       <p>Даже в подготовленном датасете у нас коэффициент атомарных к выведенным фактам всего 0.5! То есть на каждый вопрос у нас два атомарных факта.</p>
                      </blockquote>
                      <p>Что делать? Коэффициент необходимо поднять выше 3.6, чтобы модель смогла научиться решать подобные задачи! Мы решили это сделать с помощью генерации синтетических данных.</p>
                      <p>С задачей сравнения генерация проста – факты можно между собой сравнивать сколько угодно, если это логически возможно: возраст, места, время – это можно сравнивать внутри группы, но не между собой. Тут все относительно просто и правила не такие сложные, но вот с композицией все куда неоднозначнее.</p>
                      <p>Изначально набор данных из википедии выглядит примерно так:</p>
                      <figure class="full-width ">
                       <img src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/34a/97b/30b/34a97b30bc2afd3984d65bd26cc17755.png" alt="И какие новые выведенные факты тут можно придумать, если атомарные факты не связаны?" title="И какие новые выведенные факты тут можно придумать, если атомарные факты не связаны?" width="1372" height="704" sizes="(max-width: 780px) 100vw, 50vw" srcset="https://habrastorage.org/r/w780/getpro/habr/upload_files/34a/97b/30b/34a97b30bc2afd3984d65bd26cc17755.png 780w,
       https://habrastorage.org/r/w1560/getpro/habr/upload_files/34a/97b/30b/34a97b30bc2afd3984d65bd26cc17755.png 781w" loading="lazy" decode="async">
                       <div>
                        <figcaption>
                         И какие новые выведенные факты тут можно придумать, если атомарные факты не связаны?
                        </figcaption>
                       </div>
                      </figure>
                      <p>Проблема в том, что когда граф настолько разряжен, новых выведенных фактов создать не получится. Перед этим необходимо расширить имеющийся граф, чтобы количество атомарных фактов позволило сгенерировать новые выведенные факты. Можно было бы просто загрузить больше связей из самой википедии к уже имеющимся сущностям, но в жизни такое не всегда возможно, поэтому мы решили прибегнуть к более обобщенному методу: сгенерировать искусственные связи.</p>
                      <figure class="full-width ">
                       <img src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/7c7/847/c1d/7c7847c1dfd8f7b2e52c59bab6ee9951.png" alt="Отправили Питера Джексона на 150 лет в прошлое. Зато это позволило нам сгенерировать больше выведенных фактов и достичь необходимого коэффициента. " title="Отправили Питера Джексона на 150 лет в прошлое. Зато это позволило нам сгенерировать больше выведенных фактов и достичь необходимого коэффициента. " width="1354" height="690" sizes="(max-width: 780px) 100vw, 50vw" srcset="https://habrastorage.org/r/w780/getpro/habr/upload_files/7c7/847/c1d/7c7847c1dfd8f7b2e52c59bab6ee9951.png 780w,
       https://habrastorage.org/r/w1560/getpro/habr/upload_files/7c7/847/c1d/7c7847c1dfd8f7b2e52c59bab6ee9951.png 781w" loading="lazy" decode="async">
                       <div>
                        <figcaption>
                         Отправили Питера Джексона на 150 лет в прошлое. Зато это позволило нам сгенерировать больше выведенных фактов и достичь необходимого коэффициента.
                        </figcaption>
                       </div>
                      </figure>
                      <p>С одной стороны, данный подход приведет к галлюцинациям при использовании, но на данном этапе нас интересует сама возможность использования такого подхода. В теории, можно сгенерировать достоверных данные, минимизируя риск таких галлюцинаций.</p>
                      <blockquote>
                       <p>Тестировали мы данные только на реальных данных – не трогая сгенерированные атомарные и выведенные факты.</p>
                      </blockquote>
                      <p>Более подробный алгоритм синтеза данных и параметры тренировки вы можете посмотреть в нашей статье.</p>
                      <blockquote>
                       <p>Мы использовали GPT-4o-mini, чтобы преобразовать сгенерированные данные из формата графа в нормальный текст. Несмотря на все наши усилия, модель не всегда устойчиво справляется с задачей , что приводит к ошибкам: где-то выведенные факты не имеют атомарных, где-то наоборот, а где-то коэффициент меньше, чем мы ожидаем.</p>
                      </blockquote>
                      <h2>Результаты</h2>
                      <p>Для наших экспериментов мы использовали GPT2-small <strong>без предобучения </strong>(~124 млн. параметров) и тренировали ее исключительно на имеющихся атомарных и выведенных фактах, используя 1xA100 в течение 200.000 эпох с батчем 512. Каждый эксперимент занимает примерно 12 часов. И еще один момент, прежде чем мы перейдем к результатам:</p>
                      <p>В нашем исследовании мы различаем <strong>структурированные</strong> и <strong>неструктурированные</strong> атомарные данные:</p>
                      <p>В случае <strong>структурированных данных</strong> мы убрали весь лишний текст и оставили только фактическую информацию в чистом виде, например:</p>
                      <ul>
                       <li>
                        <p>Страна Лувра – Франция</p></li>
                      </ul>
                      <p>В случае <strong>неструктурированных данных</strong> мы использовали оригинальные абзацы из Википедии без дополнительной обработки, где информация часто подаётся неявно, с большим количеством деталей и контекста. Например:</p>
                      <ul>
                       <li>
                        <p>Лувр&nbsp;— один из старейших музеев с богатой историей коллекционирования художественных и исторических реликвий Франции, начиная со времён...</p></li>
                      </ul>
                      <figure class="full-width ">
                       <img src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/08f/64f/750/08f64f750600e3b8037de8a105f32ef0.png" width="5364" height="1341" sizes="(max-width: 780px) 100vw, 50vw" srcset="https://habrastorage.org/r/w780/getpro/habr/upload_files/08f/64f/750/08f64f750600e3b8037de8a105f32ef0.png 780w,
       https://habrastorage.org/r/w1560/getpro/habr/upload_files/08f/64f/750/08f64f750600e3b8037de8a105f32ef0.png 781w" loading="lazy" decode="async">
                      </figure>
                      <p>Давайте разберем получившиеся графики по одному.</p>
                      <p><strong>(a) Точность на задаче структурированного сравнения (OOD-тест). </strong>На графике сравниваются две версии модели GPT2-small: оригинальная и «грокнутая» (т.е. та, которая обучалась с расширенным набором данных и достигла феномена гроккинга). Мы видим, что точность на внераспределительных (OOD, out-of-distribution) данных поначалу практически одинаковая и быстро достигает 100%. Но затем появляется заметная разница: «грокнутая» модель продолжает улучшать свои результаты со временем, в отличие от оригинальной версии, у которой точность стагнирует.</p>
                      <p><strong>(b) Кривые обучения для задачи структурированного сравнения (IID и OOD). </strong>Здесь мы наблюдаем, что поведение на IID (In-Distribution) и OOD выборках очень схоже: после того, как модель достигает 100% точности на тренировочной выборке, точность на тестовой продолжает постепенно расти.</p>
                      <p><strong>(c) Задача структурированной композиции. </strong>В этой задаче модель показывает почти идеальную точность на ID (In-Distribution) данных, однако точность на OOD данных остаётся на исходном низком уровне и не улучшается. Это значит, что модель не смогла обобщить навык композиции на данные, которых она не видела в тренировочных цепочках.</p>
                      <p><strong>(d) Кривые обучения для задачи неструктурированного сравнения. </strong>Здесь использовались полные абзацы из Википедии без предварительной обработки. Из-за сложности таких данных её способности к обобщению на OOD-данные сильно ограничены, хотя точность на ID-данных при этом всё равно существенно улучшается со временем.</p>
                      <p>Наш подход работает! Точность «грокнутой» версии GPT2-small в целом заметно выше оригинальной и продолжает улучшаться даже после достижения 100% точности на тренировочных выборках. Для задач с <strong>структурированными</strong> <strong>данными</strong> результаты отличные практически везде, за исключением композиционных OOD-задач. Для <strong>неструктурированных</strong> <strong>данных</strong> (полные абзацы из Википедии) проблемы остаются заметными именно в OOD-тестах на сравнение.</p>
                      <p>У вас, наверное, остался вопрос: что такое <strong>OOD и ID?</strong></p>
                      <blockquote>
                       <p><strong>ID (In-Distribution) – </strong> набор вопросов, для которых модель видела и атомарные факты, и примеры их использования во время тренировки.</p>
                       <p>Нет, это не значит, что модель видела вопросы из теста. Она видела, другие комбинации на основе атомарных фактов. Условно, Питер Джексон и его жена "ушли" в тестовую выборку, но вопрос про Питер Джексона и его снятый фильм - в тренировочную.</p>
                       <p><strong>OOD (Out-of-distribution)</strong> – набор вопросов, для которых модель видела <strong>только</strong> атомарные факты во время тренировки.</p>
                      </blockquote>
                      <figure class="full-width ">
                       <img src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/338/ecb/2cc/338ecb2cc54d5d4d7171a8bed57f1554.png" alt="Метрики для разных моделей на двух наборах данных. Проблема с GPT-4o и o1-mini, как и вообще с любыми другими моделями, они все обучались на википедии, поэтому тут сложно отделять тестовые данные от нетестовых, но, несмотря на это, на некоторых задачах гроккнутая версия GPT2 побеждает всех и достигает до 100% точности." title="Метрики для разных моделей на двух наборах данных. Проблема с GPT-4o и o1-mini, как и вообще с любыми другими моделями, они все обучались на википедии, поэтому тут сложно отделять тестовые данные от нетестовых, но, несмотря на это, на некоторых задачах гроккнутая версия GPT2 побеждает всех и достигает до 100% точности." width="1036" height="416" sizes="(max-width: 780px) 100vw, 50vw" srcset="https://habrastorage.org/r/w780/getpro/habr/upload_files/338/ecb/2cc/338ecb2cc54d5d4d7171a8bed57f1554.png 780w,
       https://habrastorage.org/r/w1560/getpro/habr/upload_files/338/ecb/2cc/338ecb2cc54d5d4d7171a8bed57f1554.png 781w" loading="lazy" decode="async">
                       <div>
                        <figcaption>
                         Метрики для разных моделей на двух наборах данных. Проблема с GPT-4o и o1-mini, как и вообще с любыми другими моделями, они все обучались на википедии, поэтому тут сложно отделять тестовые данные от нетестовых, но, несмотря на это, на некоторых задачах гроккнутая версия GPT2 побеждает всех и достигает до 100% точности.
                        </figcaption>
                       </div>
                      </figure>
                      <h2>Выводы</h2>
                      <p>Несмотря на то, что нам удалось подтвердить реальность и работоспособность феномена гроккинга на реальных наборах данных, перед нами ещё остаётся немало вызовов. Среди наиболее острых проблем:</p>
                      <ul>
                       <li>
                        <p><strong>Сложность работы с неструктурированными данными:</strong><br>
                          Модель гораздо хуже справляется с задачами, где информация подаётся в виде полных абзацев без чёткой структуры.</p></li>
                       <li>
                        <p><strong>Проблемы обобщения на некоторых OOD-тестах:</strong><br>
                          Несмотря на успехи на использованных комбинациях фактов, модель в задачи композиции не может обобщить знания на OOD данных. (Почему так происходит написано тут)</p></li>
                      </ul>
                      <p>Почему так происходит? У нас есть несколько предположений:</p>
                      <ul>
                       <li>
                        <p>В неструктурированных данных атомарные факты «размазаны» по тексту и окружены большим количеством шума, что затрудняет выделение эффективных логических схем.</p></li>
                       <li>
                        <p>Из-за появления новых сложных данных первоначального коэффициента (выведенных фактов к атомарным), равного 3.6, уже недостаточно. Возможно, нам понадобится генерировать ещё больше данных, чтобы обеспечить стабильность гроккинга.</p></li>
                      </ul>
                      <p>Каждая из перечисленных выше проблем фундаментальна и заслуживает отдельного глубокого исследования, которое я планирую провести в ближайшем будущем.<br></p>
                      <h2>Хотите помочь моей статье?</h2>
                      <p>Боремся за второе место в рубрике Paper of The Day. Если вы хотите поддержать проект и меня в частности, то оставьте голос на Hugging Face, Спасибо!</p>
                      <p>👉<a href="https://huggingface.co/papers/2504.20752" rel="noopener noreferrer nofollow"> Оставить свой голос</a> 👈<br></p>
                      <p>Там вы также найдёте больше технических подробностей, описание методов генерации данных, параметры обучения и другие детали, которые я не успел включить сюда.</p>
                      <p>Также приглашаю вас в мой <a href="https://t.me/startup_custdev" rel="noopener noreferrer nofollow"><strong>Telegram-канал</strong>!</a> Там я регулярно публикую материалы про искусственный интеллект, результаты своих исследований и экспериментов, а также иногда пишу о стартапах и технологиях, связанных с ИИ.</p>
                      <p>До встречи!</p>
                     </div>
                    </div>
                   </div><!----><!---->
                  </div><!----><!---->
                 </div><!--]--><!---->
                 <div class="tm-article-presenter__meta" data-test-id="article-meta-links">
                  <div class="tm-separated-list tm-article-presenter__meta-list">
                   <span class="tm-separated-list__title">Теги:</span>
                   <ul class="tm-separated-list__list">
                    <!--[-->
                    <li class="tm-separated-list__item"><!--[--><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=[%D0%B8%D1%81%D0%BA%D1%83%D1%81%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D1%8B%D0%B9+%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82]" class="tm-tags-list__link"><span>искусственный интеллект</span></a><!--]--></li>
                    <li class="tm-separated-list__item"><!--[--><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=[%D1%82%D1%80%D0%B0%D0%BD%D1%81%D1%84%D0%BE%D1%80%D0%BC%D0%B5%D1%80%D1%8B]" class="tm-tags-list__link"><span>трансформеры</span></a><!--]--></li>
                    <li class="tm-separated-list__item"><!--[--><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=[%D0%B3%D1%80%D0%BE%D0%BA%D0%BA%D0%B8%D0%BD%D0%B3]" class="tm-tags-list__link"><span>гроккинг</span></a><!--]--></li>
                    <li class="tm-separated-list__item"><!--[--><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=[%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%2B%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5]" class="tm-tags-list__link"><span>машинное+обучение</span></a><!--]--></li>
                    <li class="tm-separated-list__item"><!--[--><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=[ai]" class="tm-tags-list__link"><span>ai</span></a><!--]--></li>
                    <li class="tm-separated-list__item"><!--[--><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=[%D1%80%D0%B0%D1%81%D1%81%D1%83%D0%B6%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5]" class="tm-tags-list__link"><span>рассуждение</span></a><!--]--></li><!--]--><!---->
                   </ul>
                  </div>
                  <div class="tm-separated-list tm-article-presenter__meta-list">
                   <span class="tm-separated-list__title">Хабы:</span>
                   <ul class="tm-separated-list__list">
                    <!--[-->
                    <li class="tm-separated-list__item"><!--[--><a href="/ru/hubs/machine_learning/" class="tm-hubs-list__link"><!--[--><span>Машинное обучение</span><!--]--></a><!--]--></li>
                    <li class="tm-separated-list__item"><!--[--><a href="/ru/hubs/artificial_intelligence/" class="tm-hubs-list__link"><!--[--><span>Искусственный интеллект</span><!--]--></a><!--]--></li>
                    <li class="tm-separated-list__item"><!--[--><a href="/ru/hubs/popular_science/" class="tm-hubs-list__link"><!--[--><span>Научно-популярное</span><!--]--></a><!--]--></li><!--]--><!---->
                   </ul>
                  </div>
                 </div><!----><!--]-->
                </article><!--]-->
               </div><!---->
              </div>
              <div style="" class="tm-article-sticky-panel" data-test-id="article-sticky-panel">
               <div class="tm-data-icons tm-data-icons tm-data-icons_space-big tm-article-sticky-panel__icons" data-test-id="article-stats-icons">
                <div class="article-rating tm-data-icons__item" data-v-86aec4a7>
                 <div class="tm-votes-lever tm-votes-lever tm-votes-lever_appearance-article votes-switcher" title="Всего голосов 17: ↑16 и ↓1" data-v-86aec4a7>
                  <button class="tm-votes-lever__button" data-test-id="votes-lever-upvote-button" title="Нравится" type="button">
                   <svg class="tm-svg-img tm-votes-lever__icon" height="24" width="24">
                    <title>
                     Нравится
                    </title><use xlink:href="/img/megazord-v28.7909a852..svg#counter-vote"></use>
                   </svg></button>
                  <div class="tm-votes-lever__score tm-votes-lever__score_appearance-article tm-votes-lever__score">
                   <!--[--><span><span class="tm-votes-lever__score-counter tm-votes-lever__score-counter_positive tm-votes-lever__score-counter" data-test-id="votes-score-counter">+18</span></span><!--]-->
                  </div>
                  <button class="tm-votes-lever__button" data-test-id="votes-lever-downvote-button" title="Не нравится" type="button">
                   <svg class="tm-svg-img tm-votes-lever__icon tm-votes-lever__icon_arrow-down" height="24" width="24">
                    <title>
                     Не нравится
                    </title><use xlink:href="/img/megazord-v28.7909a852..svg#counter-vote"></use>
                   </svg></button>
                 </div><!--teleport start--><!--teleport end--><!---->
                </div><!----><!---->
                <button class="bookmarks-button tm-data-icons__item" title="Добавить в закладки" type="button"><span class="tm-svg-icon__wrapper bookmarks-button__icon">
                  <svg class="tm-svg-img tm-svg-icon" height="24" width="24">
                   <title>
                    Добавить в закладки
                   </title><use xlink:href="/img/megazord-v28.7909a852..svg#counter-favorite"></use>
                  </svg></span><span class="bookmarks-button__counter" title="Количество пользователей, добавивших публикацию в закладки">23</span></button>
                <div class="tm-sharing tm-data-icons__item" title="Поделиться">
                 <button class="tm-sharing__button" type="button">
                  <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="tm-sharing__icon">
                   <path fill="currentColor" d="M13.8 13.8V18l7.2-6.6L13.8 5v3.9C5 8.9 3 18.6 3 18.6c2.5-4.4 6-4.8 10.8-4.8z"></path>
                  </svg></button><!--teleport start--><!--teleport end-->
                </div>
                <div class="tm-article-comments-counter-link tm-data-icons__item" title="Читать комментарии">
                 <a href="/ru/articles/907208/comments/" class="tm-article-comments-counter-link__link" data-test-id="counter-comments"><!--[-->
                  <svg class="tm-svg-img tm-article-comments-counter-link__icon" height="24" width="24">
                   <title>
                    Комментарии
                   </title><use xlink:href="/img/megazord-v28.7909a852..svg#counter-comments"></use>
                  </svg><span class="tm-article-comments-counter-link__value">4</span><!--]--></a><!---->
                </div><!--[--><!--[--><!--[--><!----><!--]--><!--]--><!--]--><!--teleport start--><!--teleport end--><!---->
               </div>
              </div>
             </div><!--[--><!--]-->
             <div class="tm-article-presenter__footer">
              <!--[--><!--[-->
              <div class="tm-article-blocks">
               <!----><!--[-->
               <section class="tm-block tm-block tm-block_spacing-bottom">
                <!----><!--[-->
                <div class="tm-block__body tm-block__body tm-block__body_variant-balanced">
                 <!--[-->
                 <div class="tm-article-author" data-test-id="article-author-info" data-async-called="true">
                  <!--[--><!--]-->
                  <div class="tm-user-card tm-user-card tm-user-card_variant-article tm-article-author__user-card" data-async-called="true">
                   <div class="tm-user-card__info-container">
                    <div class="tm-user-card__header">
                     <div class="tm-user-card__header-data">
                      <a href="/ru/users/perfect_startup/" class="tm-user-card__userpic tm-user-card__userpic_size-40">
                       <div class="tm-entity-image">
                        <img alt="" class="tm-entity-image__pic" src="//habrastorage.org/getpro/habr/avatars/32b/a19/2af/32ba192af10fcb9adaedc42807340c37.jpg">
                       </div></a>
                      <div class="tm-user-card__meta">
                       <div class="tm-counter-container karma" title=" 21 голос " data-v-f7c0e283>
                        <div class="tm-counter-container__header">
                         <!--[-->
                         <div class="karma-display positive" data-v-f7c0e283 data-v-7635202e>
                          9
                         </div><!----><!--]-->
                        </div>
                        <div class="tm-counter-container__footer">
                         <!--[-->
                         <div class="karma-text" data-v-f7c0e283>
                          Карма
                         </div><!--teleport start--><!--teleport end--><!--]-->
                        </div>
                       </div>
                       <div class="tm-counter-container" title="Рейтинг пользователя">
                        <div class="tm-counter-container__header">
                         <!--[--><!--[--><!--]-->
                         <div class="tm-votes-lever tm-votes-lever tm-votes-lever_appearance-rating">
                          <!---->
                          <div class="tm-votes-lever__score tm-votes-lever__score_appearance-rating tm-votes-lever__score">
                           <!--[--><span><span class="tm-votes-lever__score-counter tm-votes-lever__score-counter_rating tm-votes-lever__score-counter" data-test-id="votes-score-counter">18</span></span><!--]-->
                          </div><!---->
                         </div><!--]-->
                        </div>
                        <div class="tm-counter-container__footer">
                         <!--[--><span class="tm-rating__text tm-rating__text">Рейтинг</span><!--]-->
                        </div>
                       </div>
                      </div>
                     </div>
                    </div>
                    <div class="tm-user-card__info tm-user-card__info_variant-article tm-user-card__info">
                     <div class="tm-user-card__title tm-user-card__title_variant-article tm-user-card__title">
                      <span class="tm-user-card__name tm-user-card__name_variant-article tm-user-card__name">Roman Abramov</span><a href="/ru/users/perfect_startup/" class="tm-user-card__nickname tm-user-card__nickname tm-user-card__nickname_variant-article"> @perfect_startup</a><!---->
                     </div>
                     <p class="tm-user-card__short-info tm-user-card__short-info_variant-article tm-user-card__short-info" data-test-id="user-card-speciality">PhD Munich, NLP</p>
                    </div>
                   </div><!---->
                   <div class="tm-user-card__buttons tm-user-card__buttons_variant-article tm-user-card__buttons">
                    <!---->
                    <div class="tm-user-card__button">
                     <div class="tm-button-follow tm-user-card__button-follow">
                      <!---->
                      <button class="tm-button-follow__button tm-button-follow__button_big" data-test-id="follow-button" type="button">Подписаться</button>
                     </div>
                    </div><!---->
                    <div class="tm-user-card__button tm-user-card__button_write" data-test-id="user-card-conversations">
                     <svg class="tm-svg-img tm-user-card__button-icon" height="16" width="16">
                      <title>
                       Отправить сообщение
                      </title><use xlink:href="/img/megazord-v28.7909a852..svg#mail"></use>
                     </svg>
                    </div><!---->
                   </div><!---->
                  </div>
                  <div class="tm-article-author__user-contacts" data-test-id="author-contacts">
                   <!----><!----><!---->
                  </div>
                 </div><!--]-->
                </div><!--]--><!---->
               </section><!----><!--[-->
               <div class="banner-wrapper leaderboard tm-page-article__banner" style="--38f3d936:200px;--78a3cd06:auto;" data-v-f4bf0d24>
                <!--[-->
                <div class="placeholder-wrapper placeholder" data-v-f4bf0d24>
                 <!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!---->
                 <div class="adfox-banner-placeholder leaderboard" data-v-12f7bcca>
                  <div class="image loads" data-v-12f7bcca></div>
                  <div class="lines" data-v-12f7bcca>
                   <div class="line loads" data-v-12f7bcca></div>
                   <div class="line loads" data-v-12f7bcca></div>
                   <div class="line loads" data-v-12f7bcca></div>
                  </div>
                 </div><!----><!----><!---->
                </div>
                <div id="adfox_164725660339535756" class="tm-adfox-banner" data-v-f4bf0d24></div><!--]-->
               </div><!--]--><!--]-->
               <div class="tm-article-blocks__comments">
                <div id="publication-comments" class="tm-article-page-comments">
                 <div>
                  <!--[-->
                  <div class="tm-article-comments-counter-link tm-article-comments-counter-button">
                   <a href="/ru/articles/907208/comments/" class="tm-article-comments-counter-link__link tm-article-comments-counter-link__link_button-style" data-test-id="counter-comments"><!--[-->
                    <svg class="tm-svg-img tm-article-comments-counter-link__icon tm-article-comments-counter-link__icon_contrasted" height="24" width="24">
                     <title>
                      Комментарии
                     </title><use xlink:href="/img/megazord-v28.7909a852..svg#counter-comments"></use>
                    </svg><span class="tm-article-comments-counter-link__value tm-article-comments-counter-link__value_contrasted"> Комментарии 4 </span><!--]--></a><!---->
                  </div><!--]-->
                 </div>
                </div>
               </div><!--[--><!--[--><!--]-->
               <section class="tm-block tm-block tm-block_spacing-bottom">
                <header class="tm-block__header tm-block__header tm-block__header_variant-borderless">
                 <div class="tm-block__header-container">
                  <h2 class="tm-block__title tm-block__title tm-block__title_variant-large">Публикации</h2><!--[--><!--]-->
                 </div><!---->
                </header><!--[-->
                <div class="tm-block__body tm-block__body tm-block__body_variant-condensed-slim">
                 <!--[--><!--[-->
                 <div class="tm-tabs tm-tabs">
                  <div class="">
                   <!--[--><span class="tm-tabs__tab-item">
                    <button class="tm-tabs__tab-link tm-tabs__tab-link_active tm-tabs__tab-link_slim tm-tabs__tab-link">Лучшие за сутки</button></span><span class="tm-tabs__tab-item">
                    <button class="tm-tabs__tab-link tm-tabs__tab-link_slim tm-tabs__tab-link">Похожие</button></span><!--]-->
                  </div><!---->
                 </div>
                 <div class="similar-and-daily__tab-view">
                  <div class="daily-articles-list">
                   <ul class="tm-article-card-list">
                    <!--[--><!--]-->
                    <div class="tm-bordered-card">
                     <!----><!--[--><!--]-->
                    </div>
                   </ul>
                   <div class="daily-articles-block__button-container">
                    <button class="btn btn_transparent btn_small tm-button tm-button_color-horizon" type="button"><!--[--><!--[-->Показать лучшие за всё время<!--]--><!--]--></button>
                   </div>
                  </div><!---->
                 </div><!--]--><!--]-->
                </div><!--]--><!---->
               </section><!--[-->
               <div>
                <div class="placeholder-wrapper">
                 <!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!---->
                 <div class="tm-placeholder-promo">
                  <div class="tm-placeholder-promo__header">
                   <div class="tm-placeholder__line tm-placeholder__line_promo-title"></div>
                  </div>
                  <div class="tm-placeholder-promo__body">
                   <div class="tm-placeholder-promo__posts">
                    <div class="tm-placeholder-promo__post">
                     <div class="tm-placeholder-promo__image"></div>
                     <div class="tm-placeholder__line tm-placeholder__line_post-title"></div>
                    </div>
                    <div class="tm-placeholder-promo__post">
                     <div class="tm-placeholder-promo__image"></div>
                     <div class="tm-placeholder__line tm-placeholder__line_post-title"></div>
                    </div>
                    <div class="tm-placeholder-promo__post">
                     <div class="tm-placeholder-promo__image"></div>
                     <div class="tm-placeholder__line tm-placeholder__line_post-title"></div>
                    </div>
                   </div>
                   <div class="tm-placeholder-promo__dots">
                    <div class="tm-placeholder-promo__dot"></div>
                    <div class="tm-placeholder-promo__dot"></div>
                    <div class="tm-placeholder-promo__dot"></div>
                   </div>
                  </div>
                 </div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!---->
                </div>
               </div>
               <div class="placeholder-wrapper" data-async-called="true">
                <!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!---->
                <div class="tm-placeholder-inset tm-placeholder-vacancies">
                 <div class="tm-placeholder-inset__header">
                  <div class="tm-placeholder__line tm-placeholder__line_inset-header loads"></div>
                 </div>
                 <div class="tm-placeholder-inset__body">
                  <ul class="tm-placeholder-list">
                   <!--[-->
                   <li class="tm-placeholder-list__item tm-placeholder-list__item_inset">
                    <div class="tm-placeholder-list__title-container">
                     <div class="tm-placeholder__line tm-placeholder__line_item-title loads"></div>
                    </div>
                    <div class="tm-project-block-items__properties">
                     <!--[--><span class="tm-project-block-items__property-item"><span class="tm-placeholder__line loads" style="width:100px;"></span></span><span class="tm-project-block-items__property-item"><span class="tm-placeholder__line loads" style="width:100px;"></span></span><span class="tm-project-block-items__property-item"><span class="tm-placeholder__line loads" style="width:100px;"></span></span><!--]-->
                    </div></li>
                   <li class="tm-placeholder-list__item tm-placeholder-list__item_inset">
                    <div class="tm-placeholder-list__title-container">
                     <div class="tm-placeholder__line tm-placeholder__line_item-title loads"></div>
                    </div>
                    <div class="tm-project-block-items__properties">
                     <!--[--><span class="tm-project-block-items__property-item"><span class="tm-placeholder__line loads" style="width:100px;"></span></span><span class="tm-project-block-items__property-item"><span class="tm-placeholder__line loads" style="width:100px;"></span></span><span class="tm-project-block-items__property-item"><span class="tm-placeholder__line loads" style="width:100px;"></span></span><!--]-->
                    </div></li>
                   <li class="tm-placeholder-list__item tm-placeholder-list__item_inset">
                    <div class="tm-placeholder-list__title-container">
                     <div class="tm-placeholder__line tm-placeholder__line_item-title loads"></div>
                    </div>
                    <div class="tm-project-block-items__properties">
                     <!--[--><span class="tm-project-block-items__property-item"><span class="tm-placeholder__line loads" style="width:100px;"></span></span><span class="tm-project-block-items__property-item"><span class="tm-placeholder__line loads" style="width:100px;"></span></span><span class="tm-project-block-items__property-item"><span class="tm-placeholder__line loads" style="width:100px;"></span></span><!--]-->
                    </div></li>
                   <li class="tm-placeholder-list__item tm-placeholder-list__item_inset">
                    <div class="tm-placeholder-list__title-container">
                     <div class="tm-placeholder__line tm-placeholder__line_item-title loads"></div>
                    </div>
                    <div class="tm-project-block-items__properties">
                     <!--[--><span class="tm-project-block-items__property-item"><span class="tm-placeholder__line loads" style="width:100px;"></span></span><span class="tm-project-block-items__property-item"><span class="tm-placeholder__line loads" style="width:100px;"></span></span><span class="tm-project-block-items__property-item"><span class="tm-placeholder__line loads" style="width:100px;"></span></span><!--]-->
                    </div></li>
                   <li class="tm-placeholder-list__item tm-placeholder-list__item_inset">
                    <div class="tm-placeholder-list__title-container">
                     <div class="tm-placeholder__line tm-placeholder__line_item-title loads"></div>
                    </div>
                    <div class="tm-project-block-items__properties">
                     <!--[--><span class="tm-project-block-items__property-item"><span class="tm-placeholder__line loads" style="width:100px;"></span></span><span class="tm-project-block-items__property-item"><span class="tm-placeholder__line loads" style="width:100px;"></span></span><span class="tm-project-block-items__property-item"><span class="tm-placeholder__line loads" style="width:100px;"></span></span><!--]-->
                    </div></li><!--]-->
                  </ul>
                 </div>
                 <div class="tm-placeholder-inset__footer">
                  <div class="tm-placeholder__line tm-placeholder__line_inset-footer loads"></div>
                 </div>
                </div><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!---->
               </div><!--]--><!----><!--[--><!--]--><!--]-->
              </div><!--]--><!--]-->
             </div>
            </div><!--]--><!--]-->
           </div>
          </div>
          <div class="tm-page__sidebar">
           <!--[-->
           <div class="tm-layout-sidebar">
            <div class="tm-layout-sidebar__placeholder_initial"></div>
            <div class="tm-sexy-sidebar_initial tm-sexy-sidebar" style="margin-top:0px;">
             <!--[--><!--]--><!---->
             <div class="tm-layout-sidebar__ads_initial tm-layout-sidebar__ads">
              <div class="banner-wrapper half-page tm-layout-sidebar__banner tm-layout-sidebar__banner_top" style="--38f3d936:600px;--78a3cd06:auto;" data-v-f4bf0d24>
               <!--[-->
               <div class="placeholder-wrapper placeholder" data-v-f4bf0d24>
                <!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!---->
                <div class="adfox-banner-placeholder half-page" data-v-12f7bcca>
                 <div class="image loads" data-v-12f7bcca></div>
                 <div class="lines" data-v-12f7bcca>
                  <div class="line loads" data-v-12f7bcca></div>
                  <div class="line loads" data-v-12f7bcca></div>
                  <div class="line loads" data-v-12f7bcca></div>
                 </div>
                </div><!----><!----><!---->
               </div>
               <div id="adfox_164725680533065327" class="tm-adfox-banner" data-v-f4bf0d24></div><!--]-->
              </div>
             </div><!--[--><!---->
             <div></div>
             <section class="tm-block tm-block tm-block_spacing-around" data-async-called="true">
              <header class="tm-block__header tm-block__header">
               <div class="tm-block__header-container">
                <h2 class="tm-block__title tm-block__title">Работа</h2><!--[--><!--]-->
               </div><!---->
              </header><!--[-->
              <div class="tm-block__body tm-block__body">
               <!--[--><!--[-->
               <div class="tm-vacancies-block__item">
                <a class="tm-vacancies-block__vacancy-title" href="https://career.habr.com/vacancies/data_scientist" target="_blank">Data Scientist</a>
                <div class="tm-vacancies-block__vacancies-count">
                 41 вакансия
                </div>
               </div><!--]--><!--]-->
              </div><!--]-->
              <footer class="tm-block__footer">
               <!--[--><a class="tm-block-extralink" href="https://career.habr.com/catalog">Все вакансии</a><!--]-->
              </footer>
             </section>
             <section class="tm-block tm-block tm-block_spacing-around block" data-v-6f380946>
              <header class="tm-block__header tm-block__header">
               <div class="tm-block__header-container">
                <h2 class="tm-block__title tm-block__title">Ближайшие события</h2><!--[--><!--]-->
               </div><!---->
              </header><!--[-->
              <div class="tm-block__body tm-block__body">
               <!--[-->
               <div class="placeholder-wrapper" data-v-6f380946>
                <!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!---->
                <section class="tm-block tm-block tm-block_spacing-none" tabindex="-1" data-v-9caf0b82>
                 <!----><!--[-->
                 <div class="event-card-placeholder is-widget" data-v-9caf0b82>
                  <div class="image loads" data-v-9caf0b82></div>
                  <div class="info" data-v-9caf0b82>
                   <div class="date line" data-v-9caf0b82></div>
                   <div class="title line" data-v-9caf0b82></div>
                   <div class="places line" data-v-9caf0b82></div>
                   <div class="places line" data-v-9caf0b82></div>
                  </div>
                  <div class="footer widget" data-v-9caf0b82>
                   <div class="link line" data-v-9caf0b82></div>
                   <div class="categories" data-v-9caf0b82>
                    <!--[-->
                    <div class="category line" data-v-9caf0b82></div>
                    <div class="category line" data-v-9caf0b82></div>
                    <div class="category line" data-v-9caf0b82></div><!--]-->
                   </div>
                  </div>
                 </div><!--]--><!---->
                </section><!---->
               </div><!--]-->
              </div><!--]--><!---->
             </section><!--]-->
             <div class="banner-wrapper medium-rectangle tm-layout-sidebar__banner tm-layout-sidebar__banner_bottom" style="--38f3d936:250px;--78a3cd06:auto;" data-v-f4bf0d24>
              <!--[-->
              <div class="placeholder-wrapper placeholder" data-v-f4bf0d24>
               <!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!---->
               <div class="adfox-banner-placeholder medium-rectangle" data-v-12f7bcca>
                <div class="image loads" data-v-12f7bcca></div>
                <div class="lines" data-v-12f7bcca>
                 <div class="line loads" data-v-12f7bcca></div>
                 <div class="line loads" data-v-12f7bcca></div>
                 <div class="line loads" data-v-12f7bcca></div>
                </div>
               </div><!----><!----><!---->
              </div>
              <div id="adfox_164725691003361602" class="tm-adfox-banner" data-v-f4bf0d24></div><!--]-->
             </div>
            </div>
           </div><!--]-->
          </div>
         </div><!----><!--]-->
        </div>
       </div>
      </main><!---->
     </div>
     <div class="tm-footer-menu">
      <div class="tm-page-width">
       <!--[-->
       <div class="tm-footer-menu__container">
        <!--[-->
        <div class="tm-footer-menu__block">
         <p class="tm-footer-menu__block-title">Ваш аккаунт</p>
         <div class="tm-footer-menu__block-content">
          <ul class="tm-footer-menu__list">
           <!--[-->
           <li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr/?back=/ru/articles/907208/&amp;hl=ru" rel="nofollow" target="_self">Войти</a></li>
           <li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr-register/?back=/ru/articles/907208/&amp;hl=ru" rel="nofollow" target="_self">Регистрация</a></li><!--]-->
          </ul>
         </div>
        </div>
        <div class="tm-footer-menu__block">
         <p class="tm-footer-menu__block-title">Разделы</p>
         <div class="tm-footer-menu__block-content">
          <ul class="tm-footer-menu__list">
           <!--[-->
           <li class="tm-footer-menu__list-item"><a href="/ru/articles/" class="footer-menu__item-link">Статьи</a></li>
           <li class="tm-footer-menu__list-item"><a href="/ru/news/" class="footer-menu__item-link">Новости</a></li>
           <li class="tm-footer-menu__list-item"><a href="/ru/hubs/" class="footer-menu__item-link">Хабы</a></li>
           <li class="tm-footer-menu__list-item"><a href="/ru/companies/" class="footer-menu__item-link">Компании</a></li>
           <li class="tm-footer-menu__list-item"><a href="/ru/users/" class="footer-menu__item-link">Авторы</a></li>
           <li class="tm-footer-menu__list-item"><a href="/ru/sandbox/" class="footer-menu__item-link">Песочница</a></li><!--]-->
          </ul>
         </div>
        </div>
        <div class="tm-footer-menu__block">
         <p class="tm-footer-menu__block-title">Информация</p>
         <div class="tm-footer-menu__block-content">
          <ul class="tm-footer-menu__list">
           <!--[-->
           <li class="tm-footer-menu__list-item"><a href="/ru/docs/help/" class="footer-menu__item-link">Устройство сайта</a></li>
           <li class="tm-footer-menu__list-item"><a href="/ru/docs/authors/codex/" class="footer-menu__item-link">Для авторов</a></li>
           <li class="tm-footer-menu__list-item"><a href="/ru/docs/companies/corpblogs/" class="footer-menu__item-link">Для компаний</a></li>
           <li class="tm-footer-menu__list-item"><a href="/ru/docs/docs/transparency/" class="footer-menu__item-link">Документы</a></li>
           <li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/agreement/?hl=ru_RU" target="_blank">Соглашение</a></li>
           <li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/confidential/?hl=ru_RU" target="_blank">Конфиденциальность</a></li><!--]-->
          </ul>
         </div>
        </div>
        <div class="tm-footer-menu__block">
         <p class="tm-footer-menu__block-title">Услуги</p>
         <div class="tm-footer-menu__block-content">
          <ul class="tm-footer-menu__list">
           <!--[-->
           <li class="tm-footer-menu__list-item"><a href="https://company.habr.com/ru/corporate-blogs/" target="_blank">Корпоративный блог</a></li>
           <li class="tm-footer-menu__list-item"><a href="https://company.habr.com/ru/advertising/" target="_blank">Медийная реклама</a></li>
           <li class="tm-footer-menu__list-item"><a href="https://company.habr.com/ru/native-special/" target="_blank">Нативные проекты</a></li>
           <li class="tm-footer-menu__list-item"><a href="https://company.habr.com/ru/education-programs/" target="_blank">Образовательные программы</a></li>
           <li class="tm-footer-menu__list-item"><a href="https://company.habr.com/ru/hello-startup/" target="_blank">Стартапам</a></li><!--]-->
          </ul>
         </div>
        </div><!--]-->
       </div><!--]-->
      </div>
     </div>
     <div class="tm-footer">
      <div class="tm-page-width">
       <!--[-->
       <div class="tm-footer__container">
        <!---->
        <div class="tm-footer__social">
         <!--[--><a class="tm-svg-icon__wrapper tm-social-icons__icon" href="https://www.facebook.com/habrahabr.ru" rel="nofollow noopener noreferrer" target="_blank">
          <svg class="tm-svg-img tm-svg-icon" height="24" width="24">
           <title>
            Facebook
           </title><use xlink:href="/img/new-social-icons-sprite.svg#social-logo-facebook"></use>
          </svg></a><a class="tm-svg-icon__wrapper tm-social-icons__icon" href="https://twitter.com/habr_com" rel="nofollow noopener noreferrer" target="_blank">
          <svg class="tm-svg-img tm-svg-icon" height="24" width="24">
           <title>
            Twitter
           </title><use xlink:href="/img/new-social-icons-sprite.svg#social-logo-twitter"></use>
          </svg></a><a class="tm-svg-icon__wrapper tm-social-icons__icon" href="https://vk.com/habr" rel="nofollow noopener noreferrer" target="_blank">
          <svg class="tm-svg-img tm-svg-icon" height="24" width="24">
           <title>
            VK
           </title><use xlink:href="/img/new-social-icons-sprite.svg#social-logo-vk"></use>
          </svg></a><a class="tm-svg-icon__wrapper tm-social-icons__icon" href="https://telegram.me/habr_com" rel="nofollow noopener noreferrer" target="_blank">
          <svg class="tm-svg-img tm-svg-icon" height="24" width="24">
           <title>
            Telegram
           </title><use xlink:href="/img/new-social-icons-sprite.svg#social-logo-telegram"></use>
          </svg></a><a class="tm-svg-icon__wrapper tm-social-icons__icon" href="https://www.youtube.com/channel/UCd_sTwKqVrweTt4oAKY5y4w" rel="nofollow noopener noreferrer" target="_blank">
          <svg class="tm-svg-img tm-svg-icon" height="24" width="24">
           <title>
            Youtube
           </title><use xlink:href="/img/new-social-icons-sprite.svg#social-logo-youtube"></use>
          </svg></a><a class="tm-svg-icon__wrapper tm-social-icons__icon" href="https://dzen.ru/habr" rel="nofollow noopener noreferrer" target="_blank">
          <svg class="tm-svg-img tm-svg-icon" height="24" width="24">
           <title>
            Яндекс Дзен
           </title><use xlink:href="/img/new-social-icons-sprite.svg#social-logo-dzen"></use>
          </svg></a><!--]-->
        </div><!--teleport start--><!--teleport end-->
        <button class="tm-footer__link"><!----> Настройка языка</button><a href="/ru/feedback/" class="tm-footer__link">Техническая поддержка</a>
        <div class="tm-footer-copyright">
         <span class="tm-copyright"><span class="tm-copyright__years">© 2006–2025, </span><span class="tm-copyright__name"><a class="tm-copyright__link" href="https://company.habr.com/" rel="noopener" target="_blank">Habr</a></span></span>
        </div>
       </div><!--]-->
      </div>
     </div><!----><!--]-->
    </div><!---->
   </div>
   <script>window.__INITIAL_STATE__={"adblock":{"hasAcceptableAdsFilter":false,"hasAdblock":false},"articlesList":{"articlesList":{"907208":{"id":"907208","timePublished":"2025-05-06T06:13:07+00:00","isCorporative":false,"lang":"ru","titleHtml":"Как я обошел современные GPT модели с помощью GPT2-small на задачах рассуждения","leadData":{"textHtml":"\u003Cp\u003EНе так давно я уже писал статью по такому необычному явлению, как \u003Cstrong\u003Eгроккинг\u003C\u002Fstrong\u003E - отложенная генерализация. Если долго тренировать модель на наборе данных, то тестовая точность достигнет 100% и модель станет безошибочно решать задачу. Звучит круто! Но вот проблема - никто до сих пор не мог применить гроккинг на задачах из реального мира, а мы это сделали и сейчас публикуемся на крупнейшей МЛ конференции. Если интересно, как мы этого достигли, то прошу под кат. \u003C\u002Fp\u003E","imageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F8e9\u002F5fa\u002F464\u002F8e95fa464ba9ba29a11719806039d224.png","buttonTextHtml":"Читать далее","image":{"url":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F8e9\u002F5fa\u002F464\u002F8e95fa464ba9ba29a11719806039d224.png","fit":"cover","positionY":0,"positionX":0}},"editorVersion":"2.0","postType":"article","postLabels":[],"author":{"id":"4416636","alias":"perfect_startup","fullname":"Roman Abramov","avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002F32b\u002Fa19\u002F2af\u002F32ba192af10fcb9adaedc42807340c37.jpg","speciality":"PhD Munich, NLP","scoreStats":{"score":9,"votesCount":21},"rating":18,"relatedData":null,"contacts":[],"authorContacts":[],"paymentDetails":{"paymentYandexMoney":null,"paymentPayPalMe":null,"paymentWebmoney":null},"donationsMethod":null,"isInBlacklist":null,"careerProfile":null},"statistics":{"commentsCount":4,"favoritesCount":23,"readingCount":3421,"score":18,"votesCount":17,"votesCountPlus":16,"votesCountMinus":1},"hubs":[{"id":"19439","alias":"machine_learning","type":"collective","title":"Машинное обучение","titleHtml":"Машинное обучение","isProfiled":true,"relatedData":null},{"id":"21922","alias":"artificial_intelligence","type":"collective","title":"Искусственный интеллект","titleHtml":"Искусственный интеллект","isProfiled":false,"relatedData":null},{"id":"21910","alias":"popular_science","type":"collective","title":"Научно-популярное","titleHtml":"Научно-популярное","isProfiled":false,"relatedData":null}],"flows":[{"id":"1","alias":"develop","title":"Разработка","titleHtml":"Разработка"},{"id":"7","alias":"popsci","title":"Научпоп","titleHtml":"Научпоп"}],"relatedData":{"vote":null,"unreadCommentsCount":0,"bookmarked":false,"canComment":false,"canEdit":false,"canViewVotes":false,"votePlus":{"canVote":false,"isChargeEnough":false,"isKarmaEnough":false,"isVotingOver":false,"isPublicationLimitEnough":false},"voteMinus":{"canVote":false,"isChargeEnough":false,"isKarmaEnough":false,"isVotingOver":false,"isPublicationLimitEnough":false},"canModerateComments":false,"trackerSubscribed":false,"emailSubscribed":false},"textHtml":"\u003Cdiv xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1999\u002Fxhtml\"\u003E\u003Cp\u003EНе так давно я уже писал статью по такому необычному явлению, как гроккинг - отложенная генерализация. Если долго тренировать модель на наборе данных, то тестовая точность достигнет 100% и модель станет безошибочно решать задачу. Звучит круто! Но вот проблема - никто до сих пор не мог применить гроккинг на задачах из реального мира, а мы это сделали и сейчас публикуемся на крупнейшей МЛ конференции. Если интересно, как мы этого достигли, то прошу под кат. \u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw1560\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F8e9\u002F5fa\u002F464\u002F8e95fa464ba9ba29a11719806039d224.png\" alt=\" \" title=\" \" width=\"2042\" height=\"1371\" sizes=\"(max-width: 780px) 100vw, 50vw\" srcset=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F8e9\u002F5fa\u002F464\u002F8e95fa464ba9ba29a11719806039d224.png 780w,&#10;       https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw1560\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F8e9\u002F5fa\u002F464\u002F8e95fa464ba9ba29a11719806039d224.png 781w\" loading=\"lazy\" decode=\"async\"\u002F\u003E\u003Cdiv\u003E\u003Cfigcaption\u003E \u003C\u002Ffigcaption\u003E\u003C\u002Fdiv\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EПривет! Меня зовут Роман и я сейчас получаю Ph.D. в Мюнхене. Одной из тем моей кандидатской является память и гроккинг. Последняя статья как раз посвящена этому необычному явлению, с ней мы проходим на большую конференцию и боремся за первое место в \u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fpapers\u002F2504.20752\" rel=\"noopener noreferrer nofollow\"\u003EPaper of The Day\u003C\u002Fa\u003E - ваша поддержка будет незаменима.  \u003C\u002Fp\u003E\u003Ch2\u003EГроккинг\u003C\u002Fh2\u003E\u003Cp\u003EПредставим, что мы собрали данные для ИИ-калькулятора. Например, 500 примеров вида: 2 × 3 = 6, 4 × 2 = 8 и так далее. Мы обучили модель на этих данных и теперь проверяем её работу на новых примерах, которых она раньше не видела: 10 × 10 = 100, 10 × 11 = 110. Если модель верно справляется с такой задачей, значит, она успешно \u003Cstrong\u003Eобобщает\u003C\u002Fstrong\u003E полученные знания. Если же модель не дала ни одного правильного ответа, то обобщения не произошло — скорее всего, модель просто «\u003Cstrong\u003Eзапомнила\u003C\u002Fstrong\u003E» тренировочный набор данных.\u003C\u002Fp\u003E\u003Cblockquote\u003E\u003Cp\u003E\u003Cstrong\u003EОбобщение\u003C\u002Fstrong\u003E в контексте машинного обучения — это способность модели применять знания и навыки к новым, ранее не встречавшимся данным или ситуациям.\u003C\u002Fp\u003E\u003C\u002Fblockquote\u003E\u003Cp\u003EСовременные подходы в искусственном интеллекте утверждают: если модель демонстрирует \u003Cem\u003Eвысокие\u003C\u002Fem\u003E результаты на тренировочных данных, но \u003Cem\u003Eнизкие\u003C\u002Fem\u003E — на тестовых, это называется \u003Cstrong\u003Eпереобучением\u003C\u002Fstrong\u003E. Чтобы избежать этого, обычно расширяют обучающую выборку, применяют регуляризацию или используют другие техники. При наличии большого объёма тренировочных данных, как и при регуляризации, модель физически не способна всё запомнить — ей приходится искать более эффективные подходы. \u003C\u002Fp\u003E\u003Cp\u003EОднако далеко не всегда возможно или рационально расширять выборку миллионами новых примеров или применять жёсткую регуляризацию — да и не всегда эти подходы дают желаемый результат. Возникает естественный вопрос: \u003Cem\u003Eсуществуют ли альтернативные пути достижения качественного обобщения\u003C\u002Fem\u003E? Именно здесь и проявляет себя феномен «\u003Cstrong\u003Eгроккинга\u003C\u002Fstrong\u003E», предлагающий совершенно иной подход к \u003Cstrong\u003Eобобщению\u003C\u002Fstrong\u003E моделей.\u003C\u002Fp\u003E\u003Cblockquote\u003E\u003Cp\u003E\u003Cstrong\u003EГроккинг\u003C\u002Fstrong\u003E— это феномен \u003Cstrong\u003E\u003Cem\u003Eотложенного\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E обобщения модели на небольших наборах данных.\u003C\u002Fp\u003E\u003C\u002Fblockquote\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw1560\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Facd\u002F46b\u002F561\u002Facd46b561145ee5e5f106613cda92a84.png\" alt=\"Метрики на тренировочной и тестовой выборке для задачи модульного деления. Модель через 100 итерацией достигает 100%, и лишь через 1 миллион итераций достигает такого же результата на тестовой.\" title=\"Метрики на тренировочной и тестовой выборке для задачи модульного деления. Модель через 100 итерацией достигает 100%, и лишь через 1 миллион итераций достигает такого же результата на тестовой.\" width=\"1560\" height=\"1171\" sizes=\"(max-width: 780px) 100vw, 50vw\" srcset=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Facd\u002F46b\u002F561\u002Facd46b561145ee5e5f106613cda92a84.png 780w,&#10;       https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw1560\u002Fgetpro\u002Fhabr\u002Fupload_files\u002Facd\u002F46b\u002F561\u002Facd46b561145ee5e5f106613cda92a84.png 781w\" loading=\"lazy\" decode=\"async\"\u002F\u003E\u003Cdiv\u003E\u003Cfigcaption\u003EМетрики на тренировочной и тестовой выборке для задачи модульного деления. Модель через 100 итерацией достигает 100%, и лишь через 1 миллион итераций достигает такого же результата на тестовой.\u003C\u002Ffigcaption\u003E\u003C\u002Fdiv\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EИз графика можно увидеть, что отложенность у обобщения довольно значительная: модель запомнила тренировочную выборку за тысячу итераций, а для обобщения на тестовой потребовался миллион. Если перенести эти масштабы на современные языковые модели, обучение которых занимает недели или месяцы, гроккинг увеличил бы этот период до десятков лет. Неудивительно, что данному явлению уделяется так мало внимания — на данный момент оно не слишком эффективно.\u003C\u002Fp\u003E\u003Cblockquote\u003E\u003Cp\u003EЕсли интересно узнать больше, то я написал целую статью вместе с практикой - можете сами \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Farticles\u002F840136\u002F\" rel=\"noopener noreferrer nofollow\"\u003Eпопробовать пронаблюдать гроккинг\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\u003C\u002Fblockquote\u003E\u003Ch2\u003EПочему гроккинг не применяли на реальных данных?\u003C\u002Fh2\u003E\u003Cp\u003EПомимо упомянутой неэффективности, существует и другая проблема. Несмотря на то, что в некоторых исследованиях удалось добиться существенного ускорения гроккинга, остаётся вопрос о его универсальности: гроккинг проявляется далеко не на всех задачах. Более того, до сих пор нет чёткого понимания того, какие именно условия, \u003Cem\u003Eпомимо продолжительного обучения\u003C\u002Fem\u003E, необходимы для того, чтобы этот феномен вообще возник.\u003C\u002Fp\u003E\u003Cp\u003EОднако не так давно вышла статья, которая проливает свет на необходимые условия гроккинга. Авторы создали абстрактный набор данных, чтобы имитировать \u003Cstrong\u003En-шаговое рассуждение. \u003C\u002Fstrong\u003EИх набор данных состоял из задач сравнения и композиции. Для простоты понимания, превратим этот абстрактный набор данных во что-то осмысленное.\u003C\u002Fp\u003E\u003Cp\u003EНапример, у нас есть \u003Cstrong\u003Eатомарные факты:\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003Cblockquote\u003E\u003Cp\u003EАтомарные факты – это \u003Cstrong\u003Eпростые, неделимые утверждения\u003C\u002Fstrong\u003E, которые не зависят от других фактов.\u003C\u002Fp\u003E\u003C\u002Fblockquote\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003EМиша женат на Свете\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EСвета дружит с Викой \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EОтсюда можно получить \u003Cstrong\u003Eвыведенные факт:\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003Cblockquote\u003E\u003Cp\u003E\u003Cstrong\u003EВыведенные факты - \u003C\u002Fstrong\u003EЭто факты, которые \u003Cstrong\u003Eполучаются путём логической комбинации\u003C\u002Fstrong\u003E из других фактов\u003C\u002Fp\u003E\u003C\u002Fblockquote\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003Eподруга жены Миши — Вика. \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw1560\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F3e0\u002Fa69\u002F9d5\u002F3e0a699d5a1dc3f0ddf655a1a1d5ad89.png\" alt=\"Задача композиции \" title=\"Задача композиции \" width=\"1560\" height=\"733\" sizes=\"(max-width: 780px) 100vw, 50vw\" srcset=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F3e0\u002Fa69\u002F9d5\u002F3e0a699d5a1dc3f0ddf655a1a1d5ad89.png 780w,&#10;       https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw1560\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F3e0\u002Fa69\u002F9d5\u002F3e0a699d5a1dc3f0ddf655a1a1d5ad89.png 781w\" loading=\"lazy\" decode=\"async\"\u002F\u003E\u003Cdiv\u003E\u003Cfigcaption\u003EЗадача композиции \u003C\u002Ffigcaption\u003E\u003C\u002Fdiv\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EОбратите внимание на важную деталь: мы специально не упоминали Свету напрямую в формулировке вопроса, иначе задача композиции превратилась бы из двухшаговой в одношаговую. В такой задаче модели необходимо выполнить сразу несколько шагов логических рассуждений, чтобы найти конечный ответ.\u003C\u002Fp\u003E\u003Cp\u003EНапример, вопрос звучит так:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003EКто подруга жены Мишы?\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EМодели необходимо проделать два шага рассуждений:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003EПонять, на ком женат Миша (Света)\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EНайти с кем дружит Света (Вика)\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EТак вот, в задачах рассуждения для появления гроккинга необходимо иметь определенный коэффициент выведенных фактов к атомарным. Для этого набора данных он был 3.6, то есть понимаете, что выведенных фактов по сравнению с атомарными\u003Cstrong\u003E должно быть в 3.6 раза больше\u003C\u002Fstrong\u003E! Как мы понимаем, в реальном мире такое очень редко встречается.\u003C\u002Fp\u003E\u003Cblockquote\u003E\u003Cp\u003EЧтобы лучше понять, насколько все плохо, можем посмотреть вместе на типичные данные для обучения LLM: википедия. Откройте любую страницу и посчитайте, сколько на одной странице атомарных фактов и выведенных. У меня получилось 1000 атомарных фактов к 12 выведенным на случайной странице. Как мы далеки от нашего коэффициента! \u003C\u002Fp\u003E\u003C\u002Fblockquote\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw1560\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F0fc\u002F47e\u002F8da\u002F0fc47e8daab2ea31f758925cb21e696a.png\" alt=\"(Слева) График тестовой метрики от соотношения выведенных \u002F атомарных фактов. Можно заметить, что если соотношения 3.6 (то есть на 1 атомарный факт приходится 3.6 выведенных), то сходимость не наступает. В целом, чем выше соотношение, тем быстрее сходимость. (Справа) График тестовой метрики в зависимости от размера набора данных - 2, 5 и 10 тысяч. \" title=\"(Слева) График тестовой метрики от соотношения выведенных \u002F атомарных фактов. Можно заметить, что если соотношения 3.6 (то есть на 1 атомарный факт приходится 3.6 выведенных), то сходимость не наступает. В целом, чем выше соотношение, тем быстрее сходимость. (Справа) График тестовой метрики в зависимости от размера набора данных - 2, 5 и 10 тысяч. \" width=\"1560\" height=\"732\" sizes=\"(max-width: 780px) 100vw, 50vw\" srcset=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F0fc\u002F47e\u002F8da\u002F0fc47e8daab2ea31f758925cb21e696a.png 780w,&#10;       https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw1560\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F0fc\u002F47e\u002F8da\u002F0fc47e8daab2ea31f758925cb21e696a.png 781w\" loading=\"lazy\" decode=\"async\"\u002F\u003E\u003Cdiv\u003E\u003Cfigcaption\u003E(Слева) График тестовой метрики от соотношения выведенных \u002F атомарных фактов. Можно заметить, что если соотношения 3.6 (то есть на 1 атомарный факт приходится 3.6 выведенных), то сходимость не наступает. В целом, чем выше соотношение, тем быстрее сходимость. (Справа) График тестовой метрики в зависимости от размера набора данных - 2, 5 и 10 тысяч. \u003C\u002Ffigcaption\u003E\u003C\u002Fdiv\u003E\u003C\u002Ffigure\u003E\u003Ch2\u003EРаботает ли это на реальных задачах?\u003C\u002Fh2\u003E\u003Cp\u003EИменно таким вопросом я задался и решил попробовать применить данных подход к датасету \u003Ca href=\"https:\u002F\u002Fpaperswithcode.com\u002Fdataset\u002F2wikimultihopqa\" rel=\"noopener noreferrer nofollow\"\u003E2WikiMultiHopQA\u003C\u002Fa\u003E. Он составлен из страниц википедии и содержит n-шаговые рассуждения. Всего там 4 разных задачи:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003EСравнение\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EКомпозиция \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EУмозаключение\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EСвязующее сравнение \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EДля простоты, возьмем только первые два набора задач. Вот некоторые примеры из них:\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003EСравнение\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003Cp\u003EАтомарные факты:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003EСтрана Лувра – Франция\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EСтрана Эльфевой Башни – Франция\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EСоответственно, вопрос, который мы задаем модели будет:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003EНаходится ли Музей Лува и Эйфелева Башня в одной стране?\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003E\u003Cstrong\u003EКомпозиция\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003Cp\u003EАтомарные факты:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003EРежиссёр фильма «Месье Такси» — Андре Юнебель\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EАндре Юнебель умер в Ницце\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EСоответственно, вопрос, который мы задаем модели будет:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003EГде умер режиссёр фильма «Месье Такси»?\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cblockquote\u003E\u003Cp\u003EДаже в подготовленном датасете у нас коэффициент атомарных к выведенным фактам всего 0.5! То есть на каждый вопрос у нас два атомарных факта.\u003C\u002Fp\u003E\u003C\u002Fblockquote\u003E\u003Cp\u003EЧто делать? Коэффициент необходимо поднять выше 3.6, чтобы модель смогла научиться решать подобные задачи! Мы решили это сделать с помощью генерации синтетических данных. \u003C\u002Fp\u003E\u003Cp\u003EС задачей сравнения генерация проста – факты можно между собой сравнивать сколько угодно, если это логически возможно: возраст, места, время – это можно сравнивать внутри группы, но не между собой. Тут все относительно просто и правила не такие сложные, но вот с композицией все куда неоднозначнее. \u003C\u002Fp\u003E\u003Cp\u003EИзначально набор данных из википедии выглядит примерно так:\u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw1560\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F34a\u002F97b\u002F30b\u002F34a97b30bc2afd3984d65bd26cc17755.png\" alt=\"И какие новые выведенные факты тут можно придумать, если атомарные факты не связаны?\" title=\"И какие новые выведенные факты тут можно придумать, если атомарные факты не связаны?\" width=\"1372\" height=\"704\" sizes=\"(max-width: 780px) 100vw, 50vw\" srcset=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F34a\u002F97b\u002F30b\u002F34a97b30bc2afd3984d65bd26cc17755.png 780w,&#10;       https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw1560\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F34a\u002F97b\u002F30b\u002F34a97b30bc2afd3984d65bd26cc17755.png 781w\" loading=\"lazy\" decode=\"async\"\u002F\u003E\u003Cdiv\u003E\u003Cfigcaption\u003EИ какие новые выведенные факты тут можно придумать, если атомарные факты не связаны?\u003C\u002Ffigcaption\u003E\u003C\u002Fdiv\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EПроблема в том, что когда граф настолько разряжен, новых выведенных фактов создать не получится. Перед этим необходимо расширить имеющийся граф, чтобы количество атомарных фактов позволило сгенерировать новые выведенные факты. Можно было бы просто загрузить больше связей из самой википедии к уже имеющимся сущностям, но в жизни такое не всегда возможно, поэтому мы решили прибегнуть к более обобщенному методу: сгенерировать искусственные связи. \u003C\u002Fp\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw1560\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F7c7\u002F847\u002Fc1d\u002F7c7847c1dfd8f7b2e52c59bab6ee9951.png\" alt=\"Отправили Питера Джексона на 150 лет в прошлое. Зато это позволило нам сгенерировать больше выведенных фактов и достичь необходимого коэффициента. \" title=\"Отправили Питера Джексона на 150 лет в прошлое. Зато это позволило нам сгенерировать больше выведенных фактов и достичь необходимого коэффициента. \" width=\"1354\" height=\"690\" sizes=\"(max-width: 780px) 100vw, 50vw\" srcset=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F7c7\u002F847\u002Fc1d\u002F7c7847c1dfd8f7b2e52c59bab6ee9951.png 780w,&#10;       https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw1560\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F7c7\u002F847\u002Fc1d\u002F7c7847c1dfd8f7b2e52c59bab6ee9951.png 781w\" loading=\"lazy\" decode=\"async\"\u002F\u003E\u003Cdiv\u003E\u003Cfigcaption\u003EОтправили Питера Джексона на 150 лет в прошлое. Зато это позволило нам сгенерировать больше выведенных фактов и достичь необходимого коэффициента. \u003C\u002Ffigcaption\u003E\u003C\u002Fdiv\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EС одной стороны, данный подход приведет к галлюцинациям при использовании, но на данном этапе нас интересует сама возможность использования такого подхода. В теории, можно сгенерировать достоверных данные, минимизируя риск таких галлюцинаций. \u003C\u002Fp\u003E\u003Cblockquote\u003E\u003Cp\u003EТестировали мы данные только на реальных данных – не трогая сгенерированные атомарные и выведенные факты.\u003C\u002Fp\u003E\u003C\u002Fblockquote\u003E\u003Cp\u003EБолее подробный алгоритм синтеза данных и параметры тренировки вы можете посмотреть в нашей статье.\u003C\u002Fp\u003E\u003Cblockquote\u003E\u003Cp\u003EМы использовали GPT-4o-mini, чтобы преобразовать сгенерированные данные из формата графа в нормальный текст. Несмотря на все наши усилия, модель не всегда устойчиво справляется с задачей , что приводит к ошибкам: где-то выведенные факты не имеют атомарных, где-то наоборот, а где-то коэффициент меньше, чем мы ожидаем. \u003C\u002Fp\u003E\u003C\u002Fblockquote\u003E\u003Ch2\u003EРезультаты\u003C\u002Fh2\u003E\u003Cp\u003EДля наших экспериментов мы использовали GPT2-small \u003Cstrong\u003Eбез предобучения \u003C\u002Fstrong\u003E(~124 млн. параметров) и тренировали ее исключительно на имеющихся атомарных и выведенных фактах, используя 1xA100 в течение 200.000 эпох с батчем 512. Каждый эксперимент занимает примерно 12 часов. И еще один момент, прежде чем мы перейдем к результатам:\u003C\u002Fp\u003E\u003Cp\u003EВ нашем исследовании мы различаем \u003Cstrong\u003Eструктурированные\u003C\u002Fstrong\u003E и \u003Cstrong\u003Eнеструктурированные\u003C\u002Fstrong\u003E атомарные данные:\u003C\u002Fp\u003E\u003Cp\u003EВ случае \u003Cstrong\u003Eструктурированных данных\u003C\u002Fstrong\u003E мы убрали весь лишний текст и оставили только фактическую информацию в чистом виде, например:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003EСтрана Лувра – Франция\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EВ случае \u003Cstrong\u003Eнеструктурированных данных\u003C\u002Fstrong\u003E мы использовали оригинальные абзацы из Википедии без дополнительной обработки, где информация часто подаётся неявно, с большим количеством деталей и контекста. Например:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003EЛувр — один из старейших музеев с богатой историей коллекционирования художественных и исторических реликвий Франции, начиная со времён...\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw1560\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F08f\u002F64f\u002F750\u002F08f64f750600e3b8037de8a105f32ef0.png\" width=\"5364\" height=\"1341\" sizes=\"(max-width: 780px) 100vw, 50vw\" srcset=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F08f\u002F64f\u002F750\u002F08f64f750600e3b8037de8a105f32ef0.png 780w,&#10;       https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw1560\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F08f\u002F64f\u002F750\u002F08f64f750600e3b8037de8a105f32ef0.png 781w\" loading=\"lazy\" decode=\"async\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EДавайте разберем получившиеся графики по одному. \u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003E(a) Точность на задаче структурированного сравнения (OOD-тест). \u003C\u002Fstrong\u003EНа графике сравниваются две версии модели GPT2-small: оригинальная и «грокнутая» (т.е. та, которая обучалась с расширенным набором данных и достигла феномена гроккинга). Мы видим, что точность на внераспределительных (OOD, out-of-distribution) данных поначалу практически одинаковая и быстро достигает 100%. Но затем появляется заметная разница: «грокнутая» модель продолжает улучшать свои результаты со временем, в отличие от оригинальной версии, у которой точность стагнирует.\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003E(b) Кривые обучения для задачи структурированного сравнения (IID и OOD). \u003C\u002Fstrong\u003EЗдесь мы наблюдаем, что поведение на IID (In-Distribution) и OOD выборках очень схоже: после того, как модель достигает 100% точности на тренировочной выборке, точность на тестовой продолжает постепенно расти.\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003E(c) Задача структурированной композиции. \u003C\u002Fstrong\u003EВ этой задаче модель показывает почти идеальную точность на ID (In-Distribution) данных, однако точность на OOD данных остаётся на исходном низком уровне и не улучшается. Это значит, что модель не смогла обобщить навык композиции на данные, которых она не видела в тренировочных цепочках.\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003E(d) Кривые обучения для задачи неструктурированного сравнения. \u003C\u002Fstrong\u003EЗдесь использовались полные абзацы из Википедии без предварительной обработки. Из-за сложности таких данных её способности к обобщению на OOD-данные сильно ограничены, хотя точность на ID-данных при этом всё равно существенно улучшается со временем.\u003C\u002Fp\u003E\u003Cp\u003EНаш подход работает! Точность «грокнутой» версии GPT2-small в целом заметно выше оригинальной и продолжает улучшаться даже после достижения 100% точности на тренировочных выборках. Для задач с \u003Cstrong\u003Eструктурированными\u003C\u002Fstrong\u003E \u003Cstrong\u003Eданными\u003C\u002Fstrong\u003E результаты отличные практически везде, за исключением композиционных OOD-задач. Для \u003Cstrong\u003Eнеструктурированных\u003C\u002Fstrong\u003E \u003Cstrong\u003Eданных\u003C\u002Fstrong\u003E (полные абзацы из Википедии) проблемы остаются заметными именно в OOD-тестах на сравнение. \u003C\u002Fp\u003E\u003Cp\u003EУ вас, наверное, остался вопрос: что такое \u003Cstrong\u003EOOD и ID?\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\u003Cblockquote\u003E\u003Cp\u003E\u003Cstrong\u003EID (In-Distribution)  – \u003C\u002Fstrong\u003E набор вопросов, для которых модель видела и атомарные факты, и примеры их использования во время тренировки. \u003C\u002Fp\u003E\u003Cp\u003EНет, это не значит, что модель видела вопросы из теста. Она видела, другие комбинации на основе атомарных фактов. Условно, Питер Джексон и его жена \"ушли\" в тестовую выборку, но вопрос про Питер Джексона и его снятый фильм - в тренировочную.\u003C\u002Fp\u003E\u003Cp\u003E\u003Cstrong\u003EOOD (Out-of-distribution)\u003C\u002Fstrong\u003E –  набор вопросов, для которых модель видела \u003Cstrong\u003Eтолько\u003C\u002Fstrong\u003E атомарные факты во время тренировки. \u003C\u002Fp\u003E\u003C\u002Fblockquote\u003E\u003Cfigure class=\"full-width \"\u003E\u003Cimg src=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw1560\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F338\u002Fecb\u002F2cc\u002F338ecb2cc54d5d4d7171a8bed57f1554.png\" alt=\"Метрики для разных моделей на двух наборах данных. Проблема с GPT-4o и o1-mini, как и вообще с любыми другими моделями, они все обучались на википедии, поэтому тут сложно отделять тестовые данные от нетестовых, но, несмотря на это, на некоторых задачах гроккнутая версия GPT2 побеждает всех и достигает до 100% точности.\" title=\"Метрики для разных моделей на двух наборах данных. Проблема с GPT-4o и o1-mini, как и вообще с любыми другими моделями, они все обучались на википедии, поэтому тут сложно отделять тестовые данные от нетестовых, но, несмотря на это, на некоторых задачах гроккнутая версия GPT2 побеждает всех и достигает до 100% точности.\" width=\"1036\" height=\"416\" sizes=\"(max-width: 780px) 100vw, 50vw\" srcset=\"https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw780\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F338\u002Fecb\u002F2cc\u002F338ecb2cc54d5d4d7171a8bed57f1554.png 780w,&#10;       https:\u002F\u002Fhabrastorage.org\u002Fr\u002Fw1560\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F338\u002Fecb\u002F2cc\u002F338ecb2cc54d5d4d7171a8bed57f1554.png 781w\" loading=\"lazy\" decode=\"async\"\u002F\u003E\u003Cdiv\u003E\u003Cfigcaption\u003EМетрики для разных моделей на двух наборах данных. Проблема с GPT-4o и o1-mini, как и вообще с любыми другими моделями, они все обучались на википедии, поэтому тут сложно отделять тестовые данные от нетестовых, но, несмотря на это, на некоторых задачах гроккнутая версия GPT2 побеждает всех и достигает до 100% точности.\u003C\u002Ffigcaption\u003E\u003C\u002Fdiv\u003E\u003C\u002Ffigure\u003E\u003Ch2\u003EВыводы\u003C\u002Fh2\u003E\u003Cp\u003EНесмотря на то, что нам удалось подтвердить реальность и работоспособность феномена гроккинга на реальных наборах данных, перед нами ещё остаётся немало вызовов. Среди наиболее острых проблем:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003E\u003Cstrong\u003EСложность работы с неструктурированными данными:\u003C\u002Fstrong\u003E\u003Cbr\u002F\u003E Модель гораздо хуже справляется с задачами, где информация подаётся в виде полных абзацев без чёткой структуры.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003E\u003Cstrong\u003EПроблемы обобщения на некоторых OOD-тестах:\u003C\u002Fstrong\u003E\u003Cbr\u002F\u003E Несмотря на успехи на использованных комбинациях фактов, модель в задачи композиции не может обобщить знания на OOD данных. (Почему так происходит написано тут) \u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EПочему так происходит? У нас есть несколько предположений:\u003C\u002Fp\u003E\u003Cul\u003E\u003Cli\u003E\u003Cp\u003EВ неструктурированных данных атомарные факты «размазаны» по тексту и окружены большим количеством шума, что затрудняет выделение эффективных логических схем.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003Cli\u003E\u003Cp\u003EИз-за появления новых сложных данных первоначального коэффициента (выведенных фактов к атомарным), равного 3.6, уже недостаточно. Возможно, нам понадобится генерировать ещё больше данных, чтобы обеспечить стабильность гроккинга.\u003C\u002Fp\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E\u003Cp\u003EКаждая из перечисленных выше проблем фундаментальна и заслуживает отдельного глубокого исследования, которое я планирую провести в ближайшем будущем.\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Ch2\u003EХотите помочь моей статье?\u003C\u002Fh2\u003E\u003Cp\u003EБоремся за второе место в рубрике Paper of The Day. Если вы хотите поддержать проект и меня в частности, то оставьте голос на Hugging Face, Спасибо! \u003C\u002Fp\u003E\u003Cp\u003E👉\u003Ca href=\"https:\u002F\u002Fhuggingface.co\u002Fpapers\u002F2504.20752\" rel=\"noopener noreferrer nofollow\"\u003E Оставить свой голос\u003C\u002Fa\u003E 👈\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003EТам вы также найдёте больше технических подробностей, описание методов генерации данных, параметры обучения и другие детали, которые я не успел включить сюда.\u003C\u002Fp\u003E\u003Cp\u003EТакже приглашаю вас в мой \u003Ca href=\"https:\u002F\u002Ft.me\u002Fstartup_custdev\" rel=\"noopener noreferrer nofollow\"\u003E\u003Cstrong\u003ETelegram-канал\u003C\u002Fstrong\u003E!\u003C\u002Fa\u003E Там я регулярно публикую материалы про искусственный интеллект, результаты своих исследований и экспериментов, а также иногда пишу о стартапах и технологиях, связанных с ИИ.\u003C\u002Fp\u003E\u003Cp\u003EДо встречи!\u003C\u002Fp\u003E\u003C\u002Fdiv\u003E","tags":[{"titleHtml":"искусственный интеллект"},{"titleHtml":"трансформеры"},{"titleHtml":"гроккинг"},{"titleHtml":"машинное+обучение"},{"titleHtml":"ai"},{"titleHtml":"рассуждение"}],"metadata":{"stylesUrls":[],"scriptUrls":[],"shareImageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F8e9\u002F5fa\u002F464\u002F8e95fa464ba9ba29a11719806039d224.png","shareImageWidth":1200,"shareImageHeight":630,"vkShareImageUrl":"https:\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Fupload_files\u002F8e9\u002F5fa\u002F464\u002F8e95fa464ba9ba29a11719806039d224.png","schemaJsonLd":"{\"@context\":\"http:\\\u002F\\\u002Fschema.org\",\"@type\":\"Article\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Farticles\\\u002F907208\\\u002F\"},\"headline\":\"Как я обошел современные GPT модели с помощью GPT2-small на задачах рассуждения\",\"datePublished\":\"2025-05-06T09:13:07+03:00\",\"dateModified\":\"2025-05-07T01:05:45+03:00\",\"author\":{\"@type\":\"Person\",\"name\":\"Roman Abramov\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Habr\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fa_\\\u002Flk\\\u002F9m\\\u002Fa_lk9mjkccjox-zccjrpfolmkmq.png\"}},\"description\":\"Не так давно я уже писал статью по такому необычному явлению, как гроккинг - отложенная генерализация. Если долго тренировать модель на наборе данных, то тестова...\",\"url\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Farticles\\\u002F907208\\\u002F#post-content-body\",\"about\":[\"h_machine_learning\",\"h_artificial_intelligence\",\"h_popular_science\",\"f_develop\",\"f_popsci\"],\"image\":[\"https:\\\u002F\\\u002Fhabr.com\\\u002Fshare\\\u002Fpublication\\\u002F907208\\\u002F465d55abdbcaac07e7e901bce4df6c41\\\u002F\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F8e9\\\u002F5fa\\\u002F464\\\u002F8e95fa464ba9ba29a11719806039d224.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002Facd\\\u002F46b\\\u002F561\\\u002Facd46b561145ee5e5f106613cda92a84.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F3e0\\\u002Fa69\\\u002F9d5\\\u002F3e0a699d5a1dc3f0ddf655a1a1d5ad89.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F0fc\\\u002F47e\\\u002F8da\\\u002F0fc47e8daab2ea31f758925cb21e696a.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F34a\\\u002F97b\\\u002F30b\\\u002F34a97b30bc2afd3984d65bd26cc17755.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F7c7\\\u002F847\\\u002Fc1d\\\u002F7c7847c1dfd8f7b2e52c59bab6ee9951.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F08f\\\u002F64f\\\u002F750\\\u002F08f64f750600e3b8037de8a105f32ef0.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fgetpro\\\u002Fhabr\\\u002Fupload_files\\\u002F338\\\u002Fecb\\\u002F2cc\\\u002F338ecb2cc54d5d4d7171a8bed57f1554.png\"]}","metaDescription":"Не так давно я уже писал статью по такому необычному явлению, как гроккинг - отложенная генерализация. Если долго тренировать модель на наборе данных, то тестовая точность достигнет 100% и модель...","mainImageUrl":null,"amp":true,"customTrackerLinks":[]},"polls":[],"commentsEnabled":{"status":true,"reason":null},"rulesRemindEnabled":false,"votesEnabled":true,"status":"published","plannedPublishTime":null,"checked":null,"hasPinnedComments":false,"format":"review","banner":null,"multiwidget":null,"multiwidgetUuid":null,"readingTime":9,"complexity":"low","isEditorial":false}},"articlesIds":{},"isLoading":false,"pagesCount":{},"route":{},"reasonsList":null,"postReasonsList":null,"view":"cards","lastVisitedRoute":{},"ssrCommentsArticleIds":[""],"viewedPosts":[],"myFeedFilter":{"complexity":"all","score":"all","types":["articles","posts","news"]},"myFeedIsApplyFilters":false,"myFeedIsForce":false,"karma":{"userReasonsList":null}},"authorContribution":{"authors":{}},"betaTest":{"currentAnnouncement":null,"announcements":{},"announcementCards":null,"announcementComments":{},"announcementCommentThreads":{},"announcementCommentingStatuses":{},"archivedList":[]},"authorStatistics":{"articleRefs":{},"articleIds":{},"pagesCount":{},"route":{},"viewsCount":[],"maxStatsCount":{}},"career":{"seoLandings":[{"title":"Data Scientist","vacanciesCount":41,"itemUrl":"https:\u002F\u002Fcareer.habr.com\u002Fvacancies\u002Fdata_scientist","itemHubs":["bigdata","r","data_mining","python","machine_learning"]}],"hubs":"machine_learning,artificial_intelligence,popular_science"},"comments":{"articleComments":{},"articlePinnedComments":{},"searchCommentsResults":null,"pagesCount":null,"commentAccess":{},"scrollParents":{},"pageArticleComments":{"lastViewedComment":0,"postId":null,"lastCommentTimestamp":"","moderated":[],"moderatedIds":[],"commentRoute":"","idempotenceKey":""}},"companies":{"companyRefs":{},"companyIds":{},"companyTopIds":{},"pagesCount":{},"companyProfiles":{},"companiesCategories":[],"companiesCategoriesTotalCount":0,"companiesWidgets":{},"companiesWorkers":{},"companiesFans":{},"multiwidgets":{},"route":{},"isLoading":false,"companyWorkersLoading":false,"companyFansLoading":false,"multiwidgetLoading":false,"vacancies":{},"companiesGalleries":{},"companiesBanners":{},"companiesLandingVacancies":{},"companiesTechnologies":{},"workplaceInfo":null},"companyAdmin":{"companyInfo":null,"companyInfoLoading":false,"faqArticles":null,"brandingPreviewImageUrl":null,"jivoStatus":0,"adminNotifications":null,"availableInvitesCount":{}},"companyAdd":{"currentStep":"","stepsData":{},"uncompletedSteps":[],"isStepLoading":true,"isStepCommitting":false,"isInitialized":false,"agreementContent":""},"companiesContribution":{"hubs":{},"flows":{},"companyRefs":{}},"companyHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"conversation":{"messages":[],"respondent":null,"isLoadMore":false},"conversations":{"conversations":[],"pagesCount":0},"docs":{"menu":{},"articles":{},"mainMenu":[],"loading":{"main":false,"dropdown":false,"article":false}},"feature":{"isProbablyVisible":true},"fixedBanner":{"isArticleStickyPanelVisible":false,"isArticleStickyPanelAtTheBottom":false,"isFixedBannerVisible":false,"isStickyPanelIconsHidden":false},"flows":{"updates":{}},"global":{"isPwa":false,"device":"desktop","isHabrCom":true,"requestId":"e8ba87b934bcb18fef19125e3bf8faf9"},"hubs":{"hubRefs":{},"hubIds":{},"pagesCount":{},"isLoading":false,"route":{}},"hubsBlock":{"hubRefs":{},"hubIds":{}},"i18n":{"fl":"ru","hl":"ru"},"info":{"welcomePage":{},"isLoading":true},"location":{"urlStruct":{"protocol":null,"slashes":null,"auth":null,"host":null,"port":null,"hostname":null,"hash":null,"query":{},"pathname":"\u002Fru\u002Farticles\u002F907208\u002F","path":"\u002Fru\u002Farticles\u002F907208\u002F","href":"\u002Fru\u002Farticles\u002F907208\u002F"}},"me":{"user":null,"uuid":null,"ppgDemanded":false,"karmaResetInfo":{"canReincarnate":null,"wasReincarnated":null,"currentScore":null},"notes":null,"userUpdates":{"feeds":{"newPostsCount":null,"newThreadsCount":null,"newNewsCount":null,"newCount":null},"conversationUnreadCount":0},"features":null},"mostReadingList":{"mostReadingListIds":[],"mostReadingListRefs":null,"promoPost":null},"onboarding":{"currentStep":null,"stepsData":{},"stepsErrors":{},"completedSteps":[],"isStepCommitting":false,"isCommitDisabled":true},"ppa":{"articles":{},"card":null,"transactions":null,"totalTransactions":null,"isAccessible":null},"projectsBlocks":{"activeBlocks":{"vacancies":"project-block-article"}},"promoData":{"isLoading":false,"hasLoaded":false,"featurer":null,"megaposts":null,"promoLinks":null,"promoPosts":null,"sticker":null},"publicationStatistics":{"statsInfo":{},"statsFunnels":{},"statsGraph":{},"defaultSuggest":{},"suggest":{},"timeTracker":{},"isTrackingActivity":false,"isUserActive":true,"otherPublicationStats":{}},"pullRefresh":{"shouldRefresh":false},"sandbox":{"articleIds":[],"articleRefs":{},"pagesCount":null,"route":{},"lastVisitedRoute":{},"isLoading":false},"search":{"searchQueryError":null},"settingsOther":{"inputs":{"uiLang":{"errors":[],"ref":null,"value":""},"articlesLangEnglish":{"errors":[],"ref":null,"value":false},"articlesLangRussian":{"errors":[],"ref":null,"value":false},"agreement":{"errors":[],"ref":null,"value":false},"email":{"errors":[],"ref":null,"value":true},"digest":{"errors":[],"ref":null,"value":true}}},"similarList":{"similarListIds":[],"similarListRefs":null},"ssr":{"error":null,"isDataLoaded":true,"isDataLoading":false,"isHydrationFailed":false,"isServer":false},"stories":{"stories":null},"technotext":{"years":[],"technotextDocForNominees":null,"technotextDocForWinners":null,"technotextInfo":{},"technotextInfoLoading":false,"technotextWinners":{},"technotextWinnersLoading":false},"userHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"userInvites":{"availableInvites":0,"usedInvitesIds":[],"usedInvitesRefs":{},"usedInvitesPagesCount":0,"unusedInvitesIds":[],"unusedInvitesRefs":{},"unusedInvitesPagesCount":0},"userVotes":{"karmaVotesList":[],"karmaVotesPagesCount":null,"karmaVotesListLoading":false,"commentsVotesList":[],"commentsVotesPagesCount":null,"commentsVotesListLoading":false,"postsVotesList":[],"postsVotesPagesCount":null,"postsVotesListLoading":false,"userVotesList":[],"userVotesPagesCount":null,"userVotesListLoading":false},"users":{"authorRefs":{},"authorIds":{},"pagesCount":{},"authorProfiles":{},"userHubs":{},"userInvitations":{},"authorFollowers":{},"authorFollowed":{},"userSpecialization":{},"karmaStats":[],"statistics":null,"isLoading":false,"authorFollowersLoading":false,"authorFollowedLoading":false,"userHubsLoading":false,"userInvitationsLoading":false,"route":{}},"viewport":{"prevScrollY":{},"scrollY":0,"width":0},"tracker":{"notificationsLoading":false,"notificationsList":[],"notificationsPageCount":0,"pendingMarkNotificationsRead":[],"publicationsLoading":true,"publicationsList":[],"publicationsPageCount":0,"pendingDeletePublications":false,"pendingMarkPublicationsRead":false},"events":{"eventRefs":{},"eventIds":[],"pagesCount":0,"categories":[],"cities":[],"actualEvents":null,"currentEvent":null,"eventsFilter":{"city":"all","timeStarted":null,"timeEnded":null}},"wysiwyg":{"WYSIWYGRulesRefs":null},"refs":{"specializationRefs":[]},"hint":{"hints":{}}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script>
   <script src="https://assets.habr.com/habr-web/js/chunk-vendors.978df117.js" defer></script>
   <script src="https://assets.habr.com/habr-web/js/app.58b8c457.js" defer></script>
  </div>
  <div id="overlays">
   <!----><!--teleport anchor--><!----><!--teleport anchor--><!----><!--teleport anchor--><!----><!--teleport anchor--><!----><!--teleport anchor--><!----><!--teleport anchor-->
  </div>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-S28W1WC23F"></script>
  <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
    </script>
  <script type="text/javascript">
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

  </script>
  <script type="text/javascript">
      window.addEventListener('load', function () {
        setTimeout(() => {
          const img = new Image();
          img.src = 'https://vk.com/rtrg?p=VK-RTRG-421343-57vKE';
        }, 0);
      });
    </script>
 </body>
</html>